<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Functional Neuroimaging Analysis in Python: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="manifest" href="../site.webmanifest">
<link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="../assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback." style="background-color: #FFC700; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#field-testing-alpha-stage" class="external-link alert-link" style="color: #383838">
            <i aria-hidden="true" class="icon" data-feather="alert-triangle" style="border-radius: 5px"></i>
            Alpha
          </a>
          <span class="visually-hidden">This lesson is in the alpha phase, which means that it has been taught once and lesson authors are iterating on feedback.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Functional Neuroimaging Analysis in Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Functional Neuroimaging Analysis in Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Functional Neuroimaging Analysis in Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-intro-and-preprocessing.html">1. Course Overview and Introduction</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-exploring-fmriprep.html">2. Exploring Preprocessed fMRI Data from fMRIPREP</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-basic_image_manipulation.html">3. Introduction to Image Manipulation using Nilearn</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-integrating_functional_data.html">4. Integrating Functional Data</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-data-cleaning-with-nilearn.html">5. Cleaning Confounders in your Data with Nilearn</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-apply-a-parcellation.html">6. Applying Parcellations to Resting State Data</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-functional-connectivity-analysis.html">7. Functional Connectivity Analysis</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="../instructor/aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-intro-and-preprocessing"><p>Content from <a href="01-intro-and-preprocessing.html">Course Overview and Introduction</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/01-intro-and-preprocessing.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 25 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p>This document is based on the slides here <a href="https://docs.google.com/presentation/d/1er6dQcERL-Yeb5-7A29tJnmqgHNaLpTLXM3e-SmpjDg/edit#slide=id.g484812a0c7_6_1" class="external-link">Google
Slides</a></p>
<section id="functional-neuroimaging-in-python"><h2 class="section-heading">Functional Neuroimaging in Python<a class="anchor" aria-label="anchor" href="#functional-neuroimaging-in-python"></a>
</h2>
<hr class="half-width">
<p>Welcome to the <strong>Functional Neuroimaging Analysis in
Python</strong> workshop! In this workshpo we’ll get you up to speed
with the current tools and techniques used in the analysis of functional
MRI (fMRI) data. The primary goals of this workshop are:</p>
<ol style="list-style-type: decimal">
<li>Understand how neuroimaging data is stored, and how it helps us
perform analysis</li>
<li>Gain familiarity with the issues surrounding the analysis of fMRI
data, and how we can combat it in pre-processing and analysis</li>
<li>Learn how to analyze neuroimaging data, working from beginning to
end</li>
<li>Get comfortable with Python as a tool for analysis and visualization
of data</li>
</ol></section><section id="the-central-objective"><h2 class="section-heading">The Central Objective<a class="anchor" aria-label="anchor" href="#the-central-objective"></a>
</h2>
<hr class="half-width">
<p>This workshop is designed to teach you the basics and work up to
performing an <strong>intra-network functional connectivity
analysis</strong> of the <strong>Default Mode Network</strong> in
individuals with Schizophrenia and compare them to a Control
population.</p>
<p>All of this sounds fancy, but we’ll explain in depth what this looks
like in practice as the course goes along.</p>
</section><section id="a-breakdown-of-material"><h2 class="section-heading">A breakdown of material<a class="anchor" aria-label="anchor" href="#a-breakdown-of-material"></a>
</h2>
<hr class="half-width">
<p>The material covered will be:</p>
<ol style="list-style-type: decimal">
<li>Preprocessing fMRI data</li>
<li>Exploring fMRIPrep preprocessing pipeline outputs using pyBIDS</li>
<li>Introduction to Nilearn and Image manipulation</li>
<li>Integrating functional time-series data</li>
<li>Parcellating your data</li>
<li>Confound cleaning fMRI time-series signals</li>
<li>Functional Connectivity Analysis</li>
</ol></section><section id="pre-processing"><h2 class="section-heading">Pre-processing<a class="anchor" aria-label="anchor" href="#pre-processing"></a>
</h2>
<hr class="half-width">
<p>You’re a researcher who’s collected some nice MR images, and put in
some work organizing your data into a BIDS dataset. Now you’re rarin’ to
go and want to play with some data and get some science done. However,
<em>fMRI data is messy</em>, there are a ton of issues that you need to
overcome before you can even begin to analyze your data, <strong>this is
called pre-processing</strong>. Here are some of the issues:</p>
<ol style="list-style-type: decimal">
<li>We have whole head images, <em>we just want the brain</em>
</li>
<li>Your fMRI image and T1 (anatomical) image are not aligned with each
other</li>
<li>Your fMRI image is distorted due to changing magnetic fields in some
areas of the brain</li>
<li>People move, the fMRI image is misaligned <em>through time</em>
</li>
<li>Movement influences the fMRI signal itself! We want <em>brain
signals not motion signals</em>
</li>
<li>All subject images aren’t aligned with each other, and furthermore
have different brain shapes and sizes. How can we perform a group
analysis (i.e averaging etc..) if all our samples are different from one
another? We need to <em>normalize our data</em>
</li>
</ol>
<p>This seems like a lot of problems to deal with… A pictoral guide of
what dealing with these problems looks like follows below:</p>
<div class="section level3">
<h3 id="visual-guide-to-pre-processing-t1-images">Visual Guide to Pre-processing T1 images<a class="anchor" aria-label="anchor" href="#visual-guide-to-pre-processing-t1-images"></a>
</h3>
<p>First we’ll want to deal with our structural data; this is called the
<strong>T1 image</strong>. Preprocessing the T1 image consists of the
following steps:</p>
<ol style="list-style-type: decimal">
<li>Brain extraction - we want to analyze brains, not skulls</li>
<li>Normalization - since brains are different across people, we need a
method to make them look more alike so we can perform group analysis.
This is achieved using a non-linear warp which <em>squishes and
pulls</em> the brain to look like a <em>template image</em>
</li>
</ol>
<figure><img src="../fig/animated_t1_mni.gif" class="img-responsive figure mx-auto d-block" alt="T1 Normalization"></figure>
</div>
<div class="section level3">
<h3 id="visual-guide-to-pre-processing-fmri-data">Visual Guide to Pre-processing fMRI data<a class="anchor" aria-label="anchor" href="#visual-guide-to-pre-processing-fmri-data"></a>
</h3>
<p>With fMRI data things are a bit more complicated since you have to
deal with:</p>
<ol style="list-style-type: decimal">
<li>Motion across time</li>
<li>Distortion artifacts due to magnetic field inhomogeneities</li>
</ol>
<p>The following steps are required (at minimum!):</p>
<ol style="list-style-type: decimal">
<li>Brain extraction - again we’re only interested in the brain</li>
<li>Motion correction - we need to align the fMRI data <em>across
time</em>
</li>
<li>Susceptibility Distortion Correction (SDC) - we need to correct for
magnetic field inhomogeneities</li>
<li>Alignment to the T1 image - aligning to the T1 image allows us to
perform the *squishy/pully” normalization to make everyone’s brain more
alike</li>
<li>Confound regression - not only does motion <em>misalign brains</em>
it also corrupts the signal with <em>motion signal artifacts</em>, this
also needs to be cleaned!</li>
</ol>
<figure><img src="../fig/animated_fmri_preproc.gif" class="img-responsive figure mx-auto d-block" alt="fMRI Preprocessing Steps"></figure><p>So <strong>how does one begin to even accomplish this</strong>?
Traditionally, neuroimagers used a plethora of tools like, but not
limited to: <strong>FSL</strong>, <strong>AFNI</strong>,
<strong>FREESURFER</strong>, <strong>ANTS</strong>,
<strong>SPM</strong>. Each with their own quirks and file format
requirements.</p>
<p>Unfortunately this is difficult to navigate, and each tool develops
new techniques to better peform each of these pre-processing steps.
Luckily, if your data is in a <strong>BIDS Format</strong>, there exists
a tool, <a href="https://fmriprep.org" class="external-link"><strong>fMRIPrep</strong></a>,
which does this all for you while using the best methods across <em>most
of these tools</em>!. An image below from their website depicts the
processing steps they use:</p>
<figure><img src="https://github.com/oesteban/fmriprep/raw/38a63e9504ab67812b63813c5fe9af882109408e/docs/_static/fmriprep-workflow-all.png" class="img-responsive figure mx-auto d-block" alt="fMRIPrep's Workflow"></figure><p>Ultimately, fMRIPrep is an end-to-end pipeline - meaning that you
feed it your raw organized data and it’ll produce a bunch of outputs
that you can use for analysis! What follows below are explanations of
what those outputs are:</p>
<div class="section level4">
<h4 id="fmriprep-anatomical-outputs">fMRIPrep anatomical outputs<a class="anchor" aria-label="anchor" href="#fmriprep-anatomical-outputs"></a>
</h4>
<figure><img src="../fig/fmriprep_anat_out.png" class="img-static figure mx-auto d-block" alt="fMRIPrep Anatomical Outputs"></figure><div class="section level5">
<h5 id="native-space">Native Space<a class="anchor" aria-label="anchor" href="#native-space"></a>
</h5>
<ol style="list-style-type: decimal">
<li>
<strong>sub-xxxxx_T1w_brainmask.nii</strong> - a binary mask which
can be used to pull out just the brain</li>
<li>
<strong>sub-xxxxx_T1w_preproc.nii</strong> - the fully cleaned T1
image which <em>has not been normalized</em>
</li>
</ol>
</div>
<div class="section level5">
<h5 id="mni-normalized-space">MNI (Normalized) Space<a class="anchor" aria-label="anchor" href="#mni-normalized-space"></a>
</h5>
<ol style="list-style-type: decimal">
<li>
<strong>sub-xxxxx_T1w_space-MNI152NLin2009cAsym_brainmask.nii.gz</strong>
- also a brain mask, but warped to fit a template brain (the template is
MNI152NLin2009cAsym)</li>
<li>
<strong>sub-xxxxx_T1w_space-MNI152NLin2009cAsym_class-(CSF/GM/WM)_probtissue.nii.gz</strong>
- probability values for each of the tissue types. We won’t get into too
much detail with this one</li>
<li>
<strong>sub-xxxxx_T1w_space-MNI152NLin2009cAsym_preproc..nii</strong>
- the cleaned up T1 image that has been squished and warped into the
MNI152NLin2009cAsym template space</li>
</ol>
</div>
</div>
<div class="section level4">
<h4 id="fmriprep-functional-outputs">fMRIPrep functional outputs<a class="anchor" aria-label="anchor" href="#fmriprep-functional-outputs"></a>
</h4>
<figure><img src="../fig/fmriprep_func_out.png" class="img-static figure mx-auto d-block" alt="fMRIPrep Functional Outputs"></figure><p>As above we have both <strong>Native</strong> and
<strong>Normalized</strong> versions of the fMRI brain, we have a mask
of each one as well as the preprocessed fMRI brain.</p>
<p><strong>Note</strong>: These have <em>not</em> been cleaned of motion
artifacts. They have only been <em>aligned</em>, <em>distortion
corrected</em>, and <em>skull-stripped</em>.</p>
<p>fMRIPrep also outputs a
<strong>sub-xxxxx_task-…_confounds.tsv</strong> tab-delimited
spreadsheet which contains a set of <strong>nuisance regressors</strong>
that you can use to clean the <em>signal itself of motion
artifacts</em>. We’ll explore this in a later section.</p>
</div>
</div>
</section><section id="end"><h2 class="section-heading">End<a class="anchor" aria-label="anchor" href="#end"></a>
</h2>
<hr class="half-width">
<p>In the next section we’ll start exploring the outputs generated by
fMRIPrep to get a better handle of how to use them to manipulate images,
clean motion signals, and perform analysis!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>fMRI data is dirty and needs to be cleaned, aligned, and transformed
before being able to use</li>
<li>There are standards in place which will allow you to effortlessly
pull the data that you need for analysis</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-02-exploring-fmriprep"><p>Content from <a href="02-exploring-fmriprep.html">Exploring Preprocessed fMRI Data from fMRIPREP</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/02-exploring-fmriprep.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 25 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does fMRIPrep store preprocessed neuroimaging data</li>
<li>How do I access preprocessed neuroimaging data</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about fMRIPrep derivatives</li>
<li>Understand how preprocessed data is stored and how you can access
key files for analysis</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="exploring-preprocessed-fmri-data-from-fmriprep"><h2 class="section-heading">Exploring Preprocessed fMRI Data from fMRIPREP<a class="anchor" aria-label="anchor" href="#exploring-preprocessed-fmri-data-from-fmriprep"></a>
</h2>
<hr class="half-width">
<p>BIDS applications such as fMRIPREP output data into a full data
structure with strong similarity to BIDS organization principals. In
fact, there is a specification for derivatives (outputs derived from)
BIDS datasets; although this is a current work in progress, details can
be found in: <a href="https://bids-specification.readthedocs.io/en/latest/06-extensions.html" class="external-link">BIDS
Derivatives</a>.</p>
<p>In this tutorial, we’ll explore the outputs generated by fMRIPREP and
get a handle of how the data is organized from this preprocessing
pipeline</p>
<p>Luckily the semi-standardized output for fMRIPrep is organized in
such a way that the data is easily accessible using pyBIDS! We’ll first
show what the full data structure looks like, then we will provide you
with methods on how you can pull specific types of outputs using
pyBIDS.</p>
<div class="section level3">
<h3 id="the-fmriprep-derivative-data-structure">The fMRIPrep Derivative Data Structure<a class="anchor" aria-label="anchor" href="#the-fmriprep-derivative-data-structure"></a>
</h3>
<p>First let’s take a quick look at the fMRIPrep data structure:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">tree</span> <span class="at">-L</span> 1 <span class="st">'../data/ds000030/derivatives/fmriprep'</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>
../data/ds000030/derivatives/fmriprep/
├── sub-10171
├── sub-10292
├── sub-10365
├── sub-10438
├── sub-10565
├── sub-10788
├── sub-11106
├── sub-11108
├── sub-11122
├── sub-11131
├── sub-50010
├── sub-50035
├── sub-50047
├── sub-50048
├── sub-50052
├── sub-50067
├── sub-50075
├── sub-50077
├── sub-50081
└── sub-50083</code></pre>
</div>
<p>First note that inside the fMRIPrep folder, we have a folder
per-subject. Let’s take a quick look at a single subject folder:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">tree</span> <span class="st">'../data/ds000030/derivatives/fmriprep/sub-10788'</span></span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>../data/ds000030/derivatives/fmriprep/sub-10788/
├── anat
│   ├── sub-10788_desc-aparcaseg_dseg.nii.gz
│   ├── sub-10788_desc-aseg_dseg.nii.gz
│   ├── sub-10788_desc-brain_mask.json
│   ├── sub-10788_desc-brain_mask.nii.gz
│   ├── sub-10788_desc-preproc_T1w.json
│   ├── sub-10788_desc-preproc_T1w.nii.gz
│   ├── sub-10788_dseg.nii.gz
│   ├── sub-10788_from-fsnative_to-T1w_mode-image_xfm.txt
│   ├── sub-10788_from-T1w_to-fsnative_mode-image_xfm.txt
│   ├── sub-10788_label-CSF_probseg.nii.gz
│   ├── sub-10788_label-GM_probseg.nii.gz
│   ├── sub-10788_label-WM_probseg.nii.gz
│   ├── sub-10788_space-MNI152NLin2009cAsym_desc-brain_mask.json
│   ├── sub-10788_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz
│   ├── sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.json
│   ├── sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz
│   ├── sub-10788_space-MNI152NLin2009cAsym_dseg.nii.gz
│   ├── sub-10788_space-MNI152NLin2009cAsym_label-CSF_probseg.nii.gz
│   ├── sub-10788_space-MNI152NLin2009cAsym_label-GM_probseg.nii.gz
│   └── sub-10788_space-MNI152NLin2009cAsym_label-WM_probseg.nii.gz
├── func
│   ├── sub-10788_task-rest_desc-confounds_timeseries.json
│   ├── sub-10788_task-rest_desc-confounds_timeseries.tsv
│   ├── sub-10788_task-rest_from-scanner_to-T1w_mode-image_xfm.txt
│   ├── sub-10788_task-rest_from-T1w_to-scanner_mode-image_xfm.txt
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_boldref.nii.gz
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-aparcaseg_dseg.nii.gz
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-aseg_dseg.nii.gz
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-brain_mask.json
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.json
│   ├── sub-10788_task-rest_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
│   ├── sub-10788_task-rest_space-T1w_boldref.nii.gz
│   ├── sub-10788_task-rest_space-T1w_desc-aparcaseg_dseg.nii.gz
│   ├── sub-10788_task-rest_space-T1w_desc-aseg_dseg.nii.gz
│   ├── sub-10788_task-rest_space-T1w_desc-brain_mask.json
│   ├── sub-10788_task-rest_space-T1w_desc-brain_mask.nii.gz
│   ├── sub-10788_task-rest_space-T1w_desc-preproc_bold.json
│   └── sub-10788_task-rest_space-T1w_desc-preproc_bold.nii.gz
...</code></pre>
</div>
<p>As you can see above, each subject folder is organized into an
<code>anat</code> and <code>func</code> sub-folder.</p>
<p>Specifically:</p>
<ul>
<li>the <code>anat</code> folder contains the preprocessed anatomical
data. If multiple T1 files are available (all T1s even across sessions),
then these data are merged - you will always have one <code>anat</code>
folder under the subject folder</li>
<li>the <code>func</code> folder contains the preprocessed functional
data. All tasks are dumped into the same folder and like the BIDS
convention are indicated by the use of their filenames
(<code>task-[task_here]</code>)</li>
</ul>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<p>This data is single-session, so a session folder is missing here -
but with multiple sessions you will see <code>anat</code> and
<code>ses-[insert_session_here]</code> folders where each session folder
contain a <code>func</code> folder.</p>
</div>
</div>
</div>
<p>Hopefully you’re now convinced that the outputs of fMRIPREP roughly
follows BIDS organization principles. The filenames themselves give you
a full description of what each file is (check the <a href="https://docs.google.com/presentation/d/1er6dQcERL-Yeb5-7A29tJnmqgHNaLpTLXM3e-SmpjDg/edit?usp=sharing" class="external-link">slides</a>
to get an idea of what each file means!</p>
<p>Now let’s see how we can pull data in using pyBIDS!</p>
<p>Let’s import pyBIDS through the <code>bids</code> module first:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> bids</span></code></pre>
</div>
<p>We can make a <code>bids.BIDSLayout</code> object as usual by just
feeding in the fmriprep directory! However, there is one caveat… note
that fMRIPrep doesn’t exactly adhere to the <em>standard BIDS
convention</em>. It uses fields such as <code>desc-</code> which are not
part of the original BIDS specification. I.e:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">sub-10788_desc-preproc_T1w.nii.gz</span></span></code></pre>
</div>
<p>In fact, BIDS allows for <em>extensions</em> which enable you to add
additional fields to the standard BIDS convention (such as
<code>desc-</code>!). fMRIprep uses the <code>derivatives</code>
extension of the BIDS standard. pyBIDS can handle standard extensions to
the BIDS specification quite easily:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>layout <span class="op">=</span> bids.BIDSLayout(<span class="st">'../data/ds000030/derivatives/fmriprep/'</span>, config<span class="op">=</span>[<span class="st">'bids'</span>,<span class="st">'derivatives'</span>])</span></code></pre>
</div>
<p>Now that we have a layout object, we can pretend like we’re working
with a BIDS dataset! Let’s try some common commands that you would’ve
used with a BIDS dataset:</p>
<p>First, we’ll demonstrate that we can grab a list of pre-processed
subjects much like in the way we would grab subjects from a raw BIDS
dataset:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>layout.get_subjects()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['10171',
 '10292',
 '10365',
 '10438',
 '10565',
 '10788',
 '11106',
 '11108',
 '11122',
 '11131',
 '50010',
 '50035',
 '50047',
 '50048',
 '50052',
 '50067',
 '50075',
 '50077',
 '50081',
 '50083']</code></pre>
</div>
<p>We can also do the same for tasks</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>layout.get_tasks()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['rest']</code></pre>
</div>
<p>Now let’s try fetching specific files. Similar to how you would fetch
BIDS data using pyBIDS, the exact same syntax will work for fMRIPREP
derivatives. Let’s try pulling just the preprocessed anatomical
data.</p>
<p>Recall that the anatomical folder is organized as follows:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">BASH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode bash" tabindex="0"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="ex">tree</span> <span class="st">'../data/ds000030/derivatives/fmriprep/sub-10788/anat'</span>^</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>../data/ds000030/derivatives/fmriprep/sub-10788/anat
├── sub-10788_desc-aparcaseg_dseg.nii.gz
├── sub-10788_desc-aseg_dseg.nii.gz
├── sub-10788_desc-brain_mask.json
├── sub-10788_desc-brain_mask.nii.gz
├── sub-10788_desc-preproc_T1w.json
├── sub-10788_desc-preproc_T1w.nii.gz
├── sub-10788_dseg.nii.gz
├── sub-10788_from-fsnative_to-T1w_mode-image_xfm.txt
├── sub-10788_from-T1w_to-fsnative_mode-image_xfm.txt
├── sub-10788_label-CSF_probseg.nii.gz
├── sub-10788_label-GM_probseg.nii.gz
├── sub-10788_label-WM_probseg.nii.gz
├── sub-10788_space-MNI152NLin2009cAsym_desc-brain_mask.json
├── sub-10788_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz
├── sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.json
├── sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz
├── sub-10788_space-MNI152NLin2009cAsym_dseg.nii.gz
├── sub-10788_space-MNI152NLin2009cAsym_label-CSF_probseg.nii.gz
├── sub-10788_space-MNI152NLin2009cAsym_label-GM_probseg.nii.gz
└── sub-10788_space-MNI152NLin2009cAsym_label-WM_probseg.nii.gz

0 directories, 20 files</code></pre>
</div>
<p>The file that we’re interested in is of form
<code>sub-[subject]_desc-preproc_T1w.nii.gz</code>. Now we can construct
a pyBIDS call to pull these types of files specifically:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>preproc_T1 <span class="op">=</span> layout.get(datatype<span class="op">=</span><span class="st">'anat'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>, extension<span class="op">=</span><span class="st">".nii.gz"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>preproc_T1</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[&lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10438/anat/sub-10438_desc-preproc_T1w.nii.gz'&gt;,
 &lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10438/anat/sub-10438_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz'&gt;,
 &lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10788/anat/sub-10788_desc-preproc_T1w.nii.gz'&gt;,
 &lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10788/anat/sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz'&gt;,</code></pre>
</div>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout2"></a>
</h3>
<div class="callout-content">
<p>If we didn’t configure pyBIDS with
<code>config=[‘bids’,‘derivatives’]</code> then the <code>desc</code>
keyword would not work!</p>
</div>
</div>
</div>
<p>Note that we also pulled in MNI152NLin2009cAsym_preproc.nii.gz data
as well. This is data that has been transformed into MNI152NLin2009cAsym
template space. We can pull this data out by further specifying our
<code>layout.get</code> using the <code>space</code> argument:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>mni_preproc_T1 <span class="op">=</span> layout.get(datatype<span class="op">=</span><span class="st">'anat'</span>,desc<span class="op">=</span><span class="st">'preproc'</span>,extension<span class="op">=</span><span class="st">'.nii.gz'</span>,space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>mni_preproc_T1</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[&lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10438/anat/sub-10438_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz'&gt;,
 &lt;BIDSImageFile filename='/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10788/anat/sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz'&gt;,
 ...</code></pre>
</div>
<p>What if we wanted to pull out the data in T1 “native space” (it
really is a template space, since it is merged T1s)? Unfortunately for
this isn’t directly possible using <code>layout.get</code>. Instead
we’ll use a bit of python magic to pull the data that we want:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>native_preproc_T1 <span class="op">=</span> [f <span class="cf">for</span> f <span class="kw">in</span> preproc_T1 <span class="cf">if</span> f <span class="kw">not</span> <span class="kw">in</span> mni_preproc_T1]</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>native_preproc_T1</span></code></pre>
</div>
<p>Similarily fMRI data can be pulled by specifying
<code>datatype=‘func’</code> and using the <code>desc</code> argument as
appropriate:</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise 1<a class="anchor" aria-label="anchor" href="#exercise-1"></a>
</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li>Get the list of <strong>all</strong> preprocessed functional
data</li>
<li>Get the list of functional data in MNI152NLin2009cAsym space</li>
<li>Get the list of functional data in T1w space (native) Note that T1
space fMRI data can be pulled using <code>space=“T1w”</code> (this is
unlike the T1w data which required you to do some filtering)</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p><em>All the functional data</em></p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>func_data <span class="op">=</span> layout.get(datatype<span class="op">=</span><span class="st">'func'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>)</span></code></pre>
</div>
<p><em>MNI152NLin2009cAsym Functional Data</em></p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>mni_func_data <span class="op">=</span> layout.get(datatype<span class="op">=</span><span class="st">'func'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>, space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>mni_func_data</span></code></pre>
</div>
<p><em>Native/T1w space functional data</em></p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>t1w_func_data <span class="op">=</span> layout.get(datatype<span class="op">=</span><span class="st">'func'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>, space<span class="op">=</span><span class="st">'T1w'</span>)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>t1w_func_data </span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Now that we have a handle on how fMRIPREP preprocessed data is
organized and how we can pull this data. Let’s start working with the
actual data itself!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>fMRIPrep stores preprocessed data in a ‘BIDS-like’ fashion</li>
<li>You can pull files using pyBIDS much like how you can navigate raw
BIDS data</li>
</ul>
</div>
</div>
</div>
</div>
</section></section><section id="aio-03-basic_image_manipulation"><p>Content from <a href="03-basic_image_manipulation.html">Introduction to Image Manipulation using Nilearn</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/03-basic_image_manipulation.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 45 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can be perform arithmetic operations on MR images</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use Nilearn to perform masking and mathematical operations</li>
<li>Learn how to resample across modalities for image viewing and
manipulation</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="introduction"><h2 class="section-heading">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>Nilearn is a functional neuroimaging analysis and visualization
library that wraps up a whole bunch of high-level operations (machine
learning, statistical analysis, data cleaning, etc…) in easy-to-use
commands. The neat thing about Nilearn is that it implements Nibabel
under the hood. What this means is that everything you do in Nilearn can
be represented by performing a set of operations on Nibabel objects.
This has the important consequence of allowing you, yourself to perform
high-level operations (like resampling) using Nilearn then dropping into
Nibabel for more custom data processing then jumping back up to Nilearn
for interactive image viewing. Pretty cool!</p>
</section><section id="setting-up"><h2 class="section-heading">Setting up<a class="anchor" aria-label="anchor" href="#setting-up"></a>
</h2>
<hr class="half-width">
<p>The first thing we’ll do is to important some Python modules that
will allow us to use Nilearn:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> nimg</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> nplot</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> bids <span class="im">import</span> BIDSLayout</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#for inline visualization in jupyter notebook</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="op">%</span>matplotlib inline </span></code></pre>
</div>
<p>Notice that we imported two things:</p>
<ol style="list-style-type: decimal">
<li>
<code>image as nimg</code> - allows us to load NIFTI images using
nibabel under the hood</li>
<li>
<code>plotting as nplot</code>- allows us to using Nilearn’s
plotting library for easy visualization</li>
</ol>
<p>First let’s grab some data from where we downloaded our
<strong>FMRIPREP</strong> outputs. Note that we’re using the argument
<code>return_type=‘file’</code> so that pyBIDS gives us file paths
directly rather than the standard BIDSFile objects</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co">#Base directory for fmriprep output</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>fmriprep_dir <span class="op">=</span> <span class="st">'../data/ds000030/derivatives/fmriprep/'</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>layout<span class="op">=</span> BIDSLayout(fmriprep_dir, config<span class="op">=</span>[<span class="st">'bids'</span>,<span class="st">'derivatives'</span>])</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>T1w_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>, datatype<span class="op">=</span><span class="st">'anat'</span>,</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>					   desc<span class="op">=</span><span class="st">'preproc'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>,</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>					   return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>					   </span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>brainmask_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>, datatype<span class="op">=</span><span class="st">'anat'</span>, suffix<span class="op">=</span><span class="st">"mask"</span>,</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>                             desc<span class="op">=</span><span class="st">'brain'</span>, extension<span class="op">=</span><span class="st">'.nii.gz'</span>,</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>                             return_type<span class="op">=</span><span class="st">'file'</span>)</span></code></pre>
</div>
<p>Here we used pyBIDS (as introduced in earlier sections) to pull a
single participant. Specifically, we pulled all preprocessed
(MNI152NLin2009cAsym, and T1w) anatomical files as well as their
respective masks. Let’s quickly view these files for review:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">#Display preprocessed files inside of anatomy folder</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>T1w_files</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>['/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10788/anat/sub-10788_desc-preproc_T1w.nii.gz',
 '/home/jerry/projects/workshops/SDC-BIDS-fMRI/data/ds000030/derivatives/fmriprep/sub-10788/anat/sub-10788_space-MNI152NLin2009cAsym_desc-preproc_T1w.nii.gz']</code></pre>
</div>
<p>Now that we have our files set up, let’s start performing some basic
image operations.</p>
<div class="section level3">
<h3 id="basic-image-operations">Basic Image Operations<a class="anchor" aria-label="anchor" href="#basic-image-operations"></a>
</h3>
<p>In this section we’re going to deal with the following files:</p>
<ol style="list-style-type: decimal">
<li>
<code>sub-10171_desc-preproc_T1w.nii.gz</code> - the T1 image in
native space</li>
<li>
<code>sub-10171_desc-brain_mask.nii.gz</code> - a mask with 1’s
representing the brain and 0’s elsewhere.</li>
</ol>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>t1 <span class="op">=</span> T1w_files[<span class="dv">0</span>]</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>bm <span class="op">=</span> brainmask_files[<span class="dv">0</span>]</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>t1_img <span class="op">=</span> nimg.load_img(t1)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>bm_img <span class="op">=</span> nimg.load_img(bm)</span></code></pre>
</div>
<p>Using the <code>plotting</code> module (which we’ve aliased as
<code>nplot</code>), we can view our MR image:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>nplot.plot_anat(t1_img)</span></code></pre>
</div>
<figure><img src="../fig/t1_img.png" class="img-responsive figure mx-auto d-block" alt="Nilearn antomical plotting"></figure><p>This gives just a still image of the brain. We can also view the
brain more interactively using the <code>view_img</code> function. It
will require some additional settings however:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>nplot.view_img(t1_img,</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>               bg_img<span class="op">=</span><span class="va">False</span>, <span class="co"># Disable using a standard image as the background</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>               cmap<span class="op">=</span><span class="st">'Greys_r'</span>, <span class="co"># Set color scale so white matter appears lighter than grey</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>               symmetric_cmap<span class="op">=</span><span class="va">False</span>, <span class="co"># We don't have negative values</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>               threshold<span class="op">=</span><span class="st">"auto"</span>, <span class="co"># Clears out the background</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>              )</span></code></pre>
</div>
<p>Try clicking and dragging the image in each of the views that are
generated!</p>
<p>Try viewing the mask as well!</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>nplot.plot_anat(bm_img)</span></code></pre>
</div>
<div class="section level4">
<h4 id="arithmetic-operations">Arithmetic Operations<a class="anchor" aria-label="anchor" href="#arithmetic-operations"></a>
</h4>
<p>Let’s start performing some image operations. The simplest operations
we can perform is <strong>element-wise</strong>, what this means is that
we want to perform some sort of mathematical operation on each
<strong>voxel</strong> of the MR image. Since <em>voxels are represented
in a 3D array, this is equivalent to performing an operation on each
element (i,j,k) of a 3D array</em>. Let’s try inverting the image, that
is, flip the colour scale such that all blacks appear white and
vice-versa. To do this, we’ll use the method</p>
<p><code>nimg.math_img(formula, **imgs)</code> Where:</p>
<ul>
<li>
<code>formula</code> is a mathematical expression such as
<code>'a+1'</code>
</li>
<li>
<code>**imgs</code> is a set of key-value pairs linking variable
names to images. For example <code>a=T1</code>
</li>
</ul>
<p>In order to invert the image, we can simply flip the sign which will
set the most positive elements (white) to the most negatve elements
(black), and the least positives elements (black) to the least negative
elements (white). This effectively flips the colour-scale:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>invert_img <span class="op">=</span> nimg.math_img(<span class="st">'-a'</span>, a<span class="op">=</span>t1_img)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>nplot.plot_anat(invert_img)</span></code></pre>
</div>
<figure><img src="../fig/invert_img.png" class="img-responsive figure mx-auto d-block" alt="Nilearn image math example output"></figure><blockquote>
<blockquote>
<p>Alternatively we don’t need to first load in our <code>t1_img</code>
using <code>img.load_img</code>. Instead we can feed in a path to
<code>img.math_img</code>:</p>
</blockquote>
</blockquote>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<pre><code><span><span class="va">invert_img</span> <span class="op">=</span> <span class="fu">nimg.math_img</span><span class="op">(</span><span class="st">'-a'</span>, a<span class="op">=</span><span class="va">t1</span><span class="op">)</span></span>
<span><span class="fu">nplot.plot_anat</span><span class="op">(</span><span class="va">invert_img</span><span class="op">)</span></span></code></pre>
<p>This will yield the same result!</p>
</div>
</div>
</div>
</div>
<div class="section level4">
<h4 id="applying-a-mask">Applying a Mask<a class="anchor" aria-label="anchor" href="#applying-a-mask"></a>
</h4>
<p>Let’s extend this idea of applying operations to each element of an
image to multiple images. Instead of specifying just one image like the
following:</p>
<p><code>nimg.math_img('a+1',a=img_a)</code></p>
<p>We can specify multiple images by tacking on additional
variables:</p>
<p><code>nimg.math_img('a+b', a=img_a, b=img_b)</code></p>
<p>The key requirement here is that when dealing with multiple images,
that the <em>size</em> of the images must be the same. The reason being
is that we’re deaing with <strong>element-wise</strong> operations. That
means that some voxel (i,j,k) in <code>img_a</code> is being paired with
some voxel (i,j,k) in <code>img_b</code> when performing operations. So
every voxel in <code>img_a</code> must have some pair with a voxel in
<code>img_b</code>; sizes must be the same.</p>
<p>We can take advantage of this property when masking our data using
multiplication. Masking works by multipling a raw image (our
<code>T1</code>), with some mask image (our <code>bm</code>). Whichever
voxel (i,j,k) has a value of 0 in the mask multiplies with voxel (i,j,k)
in the raw image resulting in a product of 0. Conversely, any voxel
(i,j,k) in the mask with a value of 1 multiplies with voxel (i,j,k) in
the raw image resulting in the same value. Let’s try this out in
practice and see what the result is:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>masked_t1 <span class="op">=</span> nimg.math_img(<span class="st">'a*b'</span>, a<span class="op">=</span>t1, b<span class="op">=</span>bm)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>nplot.plot_anat(masked_t1)</span></code></pre>
</div>
<figure><img src="../fig/masked_t1.png" class="img-responsive figure mx-auto d-block" alt="Nilearn image masking output"></figure><p>As you can see areas where the mask image had a value of 1 were
retained, everything else was set to 0</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise #1<a class="anchor" aria-label="anchor" href="#exercise-1"></a>
</h3>
<div class="callout-content">
<p>Try applying the mask such that the brain is removed, but the rest of
the head is intact! <em>Hint:</em> Remember that a mask is composed of
0’s and 1’s, where parts of the data labelled 1 are regions to keep, and
parts of the data that are 0, are to throw away. You can do this in 2
steps:</p>
<ol style="list-style-type: decimal">
<li>Switch the 0’s and 1’s using an equation (simple
addition/substraction) or condition (like x == 0).</li>
<li>Apply the mask</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Invert the mask</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>inverted_mask <span class="op">=</span> nimg.math_img(<span class="st">'1-x'</span>, x<span class="op">=</span>bm)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>nplot.plot_anat(inverted_mask)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Apply the mask</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>inverted_mask_t1 <span class="op">=</span> nimg.math_img(<span class="st">'a*b'</span>, a<span class="op">=</span>t1, b<span class="op">=</span>inverted_mask)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>nplot.plot_anat(inverted_mask_t1)</span></code></pre>
</div>
<figure><img src="../fig/inverted_mask_t1.png" class="img-responsive figure mx-auto d-block" alt="Episode 03 Exercise 1 inverted mask"></figure>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="slicing">Slicing<a class="anchor" aria-label="anchor" href="#slicing"></a>
</h3>
<p>Recall that our data matrix is organized in the following manner:</p>
<div class="section level4">
<h4 id="section">
<insert image here></insert><a class="anchor" aria-label="anchor" href="#section"></a>
</h4>
<figure><img src="../fig/slicing.png" class="img-responsive figure mx-auto d-block" alt="3D Array Representation"></figure><p>Slicing does exactly what it seems to imply. Given our 3D volume, we
can pull out 2D subsets (called “slices”). Here’s an example of slicing
moving from left to right via an animated GIF:</p>
</div>
<div class="section level4">
<h4 id="section-1">
<insert image here></insert><a class="anchor" aria-label="anchor" href="#section-1"></a>
</h4>
<figure><img src="../fig/animated_slicing.gif" class="img-responsive figure mx-auto d-block" alt="Animated Slicing of T1"></figure><p>What you see here is a series of 2D images that start from the left,
and move toward the right. Each frame of this GIF is a slice - a 2D
subset of a 3D volume. Slicing can be useful for cases in which you’d
want to loop through each MR slice and perform a computation;
importantly in functional imaging data slicing is useful for pulling out
timepoints as we’ll see later!</p>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout2"></a>
</h3>
<div class="callout-content">
<p>Sourced from: <a href="https://en.wikipedia.org/wiki/Neuroimaging#/media/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif" class="external-link">https://en.wikipedia.org/wiki/Neuroimaging#/media/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif</a></p>
</div>
</div>
</div>
<p>Slicing is done easily on an image file using the attribute
<code>.slicer</code> of a Nilearn <code>image</code> object. For example
we can grab the <span class="math inline">\(10^{\text{th}}\)</span>
slice along the x axis as follows:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>x_slice <span class="op">=</span> t1_img.slicer[<span class="dv">10</span>:<span class="dv">11</span>,:,:]</span></code></pre>
</div>
<p>The statement <span class="math inline">\(10:11\)</span> is
intentional and is required by <code>.slicer</code>. Alternatively we
can slice along the x-axis using the data matrix itself:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>t1_data <span class="op">=</span> t1_img.get_data()</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>x_slice <span class="op">=</span> t1_data[<span class="dv">10</span>,:,:]</span></code></pre>
</div>
<p>This will yield the same result as above. Notice that when using the
<code>t1_data</code> array we can just specify which slice to grab
instead of using <code>:</code>. We can use slicing in order to modify
visualizations. For example, when viewing the T1 image, we may want to
specify at which slice we’d like to view the image. This can be done by
specifying which coordinates to <em>cut</em> the image at:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>nplot.plot_anat(t1_img,cut_coords<span class="op">=</span>(<span class="dv">50</span>,<span class="dv">30</span>,<span class="dv">20</span>))</span></code></pre>
</div>
<p>The <code>cut_coords</code> option specifies 3 numbers:</p>
<ul>
<li>The first number says cut the X coordinate at slice 50 and display
(sagittal view in this case!)</li>
<li>The second number says cut the Y coordinate at slice 30 and display
(coronal view)</li>
<li>The third number says cut the Z coordinate at slice 20 and display
(axial view)</li>
</ul>
<p>Remember <code>nplot.plot_anat</code> yields 3 images, therefore
<code>cut_coords</code> allows you to display where to take
cross-sections of the brain from different perspectives (axial,
sagittal, coronal)</p>
<p>This covers the basics of image manipulation using T1 images. To
review in this section we covered:</p>
<ul>
<li>Basic image arithmetic</li>
<li>Visualization</li>
<li>Slicing</li>
</ul>
<p>In the next section we will cover how to integrate additional
modalities (functional data) to what we’ve done so far using
<code>Nilearn</code>. Then we can start using what we’ve learned in
order to perform analysis and visualization!</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>MR images are essentially 3D arrays where each voxel is represented
by an (i,j,k) index</li>
<li>Nilearn is Nibabel under the hood, knowing how Nibabel works is key
to understanding Nilearn</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="aio-04-integrating_functional_data"><p>Content from <a href="04-integrating_functional_data.html">Integrating Functional Data</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/04-integrating_functional_data.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 45 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How is fMRI data represented</li>
<li>How can we access fMRI data along spatial and temporal
dimensions</li>
<li>How can we integrate fMRI and structural MRI together</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Extend the idea of slicing to 4 dimensions</li>
<li>Apply resampling to T1 images to combine them with fMRI data</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="integrating-functional-data"><h2 class="section-heading">Integrating Functional Data<a class="anchor" aria-label="anchor" href="#integrating-functional-data"></a>
</h2>
<hr class="half-width">
<p>So far most of our work has been examining anatomical images - the
reason being is that it provides a nice visual way of exploring the
effects of data manipulation and visualization is easy. In practice, you
will most likely not analyze anatomical data using <code>nilearn</code>
since there are other tools that are better suited for that kind of
analysis (freesurfer, connectome-workbench, mindboggle, etc…).</p>
<p>In this notebook we’ll finally start working with functional MR data
- the modality of interest in this workshop. First we’ll cover some
basics about how the data is organized (similar to T1s but slightly more
complex), and then how we can integrate our anatomical and functional
data together using tools provided by <code>nilearn</code></p>
<p>Functional data consists of full 3D brain volumes that are
<em>sampled</em> at multiple time points. Therefore you have a sequence
of 3D brain volumes, stepping through sequences is stepping through time
and therefore time is our 4th dimension! Here’s a visualization to make
this concept more clear:</p>
<figure><img src="../fig/4D_array.png" class="img-responsive figure mx-auto d-block" alt="4D Array Representation"></figure><p>Each index along the 4th dimensions (called TR for “Repetition Time”,
or Sample) is a full 3D scan of the brain. Pulling out volumes from
4-dimensional images is similar to that of 3-dimensional images except
you’re now dealing with:</p>
<p><code> nimg.slicer[x,y,z,time] </code>!</p>
<p>Let’s try a couple of examples to familiarize ourselves with dealing
with 4D images. But first, let’s pull some functional data using
PyBIDS!</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt <span class="co">#to enable plotting within notebook</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> nimg</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> nplot</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> bids.layout <span class="im">import</span> BIDSLayout</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code></pre>
</div>
<p>These are the usual imports. Let’s now pull some structural
<em>and</em> functional data using pyBIDS.</p>
<p>We’ll be using functional files in MNI space rather than T1w space.
Recall, that MNI space data is data that was been warped into standard
space. These are the files you would typically use for a group-level
functional imaging analysis!</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>fmriprep_dir <span class="op">=</span> <span class="st">'../data/ds000030/derivatives/fmriprep/'</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>layout<span class="op">=</span>BIDSLayout(fmriprep_dir, validate<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>                  config<span class="op">=</span>[<span class="st">'bids'</span>,<span class="st">'derivatives'</span>])</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>T1w_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>,</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>                       datatype<span class="op">=</span><span class="st">'anat'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>,</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>                       space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>                       extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>                      return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>brainmask_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>,</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>                             datatype<span class="op">=</span><span class="st">'anat'</span>, suffix<span class="op">=</span><span class="st">'mask'</span>,</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>                             desc<span class="op">=</span><span class="st">'brain'</span>,</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>                             space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>                             extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>                            return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>func_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>,</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>                        datatype<span class="op">=</span><span class="st">'func'</span>, desc<span class="op">=</span><span class="st">'preproc'</span>,</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>                       space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>                       extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>                       return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>func_mask_files <span class="op">=</span> layout.get(subject<span class="op">=</span><span class="st">'10788'</span>,</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>                             datatype<span class="op">=</span><span class="st">'func'</span>, suffix<span class="op">=</span><span class="st">'mask'</span>,</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>                             desc<span class="op">=</span><span class="st">'brain'</span>,</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>                             space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>                             extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>                            return_type<span class="op">=</span><span class="st">'file'</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>func_mni <span class="op">=</span> func_files[<span class="dv">0</span>]</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>func_mni_img <span class="op">=</span> nimg.load_img(func_mni)</span></code></pre>
</div>
</section><section id="fmri-dimensions"><h2 class="section-heading">fMRI Dimensions<a class="anchor" aria-label="anchor" href="#fmri-dimensions"></a>
</h2>
<hr class="half-width">
<p>First note that fMRI data contains both spatial dimensions (x,y,z)
and a temporal dimension (t). This would mean that we require 4
dimensions in order to represent our data. Let’s take a look at the
shape of our data matrix to confirm this intuition:</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>func_mni_img.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(65, 77, 49, 152)</code></pre>
</div>
<p>Notice that the Functional MR scan contains <em>4 dimensions</em>.
This is in the form of <span class="math inline">\((x,y,z,t)\)</span>,
where <span class="math inline">\(t\)</span> is time. We can use slicer
as usual where instead of using 3 dimensions we use 4.</p>
<p>For example:</p>
<p><code> func.slicer[x,y,z] </code></p>
<p>vs.</p>
<p><code> func.slicer[x,y,z,t] </code></p>
<div id="exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise" class="callout-inner">
<h3 class="callout-title">Exercise<a class="anchor" aria-label="anchor" href="#exercise"></a>
</h3>
<div class="callout-content">
<p>Try pulling out the 5th TR and visualizing it using
<code>nplot.view_img</code>.</p>
<p>Remember that <code>nplot.view_img</code> provides an interactive
view of the brain, try scrolling around!</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co">#Pull the 5th TR</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>func_vol5 <span class="op">=</span> func_mni_img.slicer[:,:,:,<span class="dv">4</span>]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>nplot.view_img(func_vol5)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>You may also use <code>nplot.plot_epi</code>. <code>plot_epi</code>
is exactly the same as <code>plot_anat</code> except it displays using
colors that make more sense for functional images…</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">#Pull the 5th TR</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>nplot.plot_epi(func_vol5)</span></code></pre>
</div>
<figure><img src="../fig/fmri_data.png" class="img-responsive figure mx-auto d-block" alt="Visual of fMRI EPI Data"></figure></section><section id="what-fmri-actually-represents"><h2 class="section-heading">What fMRI actually represents<a class="anchor" aria-label="anchor" href="#what-fmri-actually-represents"></a>
</h2>
<hr class="half-width">
<p>We’ve represented fMRI as a snapshot of MR signal over multiple
timepoints. This is a useful way of understanding the organization of
fMRI, however it isn’t typically how we think about the data when we
analyze fMRI data. fMRI is typically thought of as
<strong>time-series</strong> data. We can think of each voxel (x,y,z
coordinate) as having a time-series of length T. The length T represents
the number of volumes/timepoints in the data. Let’s pick an example
voxel and examine its time-series using
<code>func_mni_img.slicer</code>:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">#Pick one voxel at coordinate (60,45,88)</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>single_vox <span class="op">=</span> func_mni_img.slicer[<span class="dv">59</span>:<span class="dv">60</span>,<span class="dv">45</span>:<span class="dv">46</span>,<span class="dv">30</span>:<span class="dv">31</span>,:].get_data()</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>single_vox.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(1, 1, 1, 152)</code></pre>
</div>
<p>As you can see we have 1 element in (x,y,z) dimension representing a
single voxel. In addition, we have 152 elements in the fourth dimension.
In totality, this means we have a single voxel with 152 timepoints.
Dealing with 4 dimensional arrays are difficult to work with - since we
have a single element across the first 3 dimensions we can squish this
down to a 1 dimensional array with 152 time-points. We no longer need
the first 3 spatial dimensions since we’re only looking at one voxel and
don’t need (x,y,z) anymore:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>single_vox <span class="op">=</span> single_vox.flatten()</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>single_vox.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(152,)</code></pre>
</div>
<p>Here we’ve pulled out a voxel at a specific coordinate at every
single time-point. This voxel has a single value for each timepoint and
therefore is a time-series. We can visualize this time-series signal by
using a standard python plotting library. We won’t go into too much
detail about python plotting, the intuition about what the data looks
like is what is most important:</p>
<p>First let’s import the standard python plotting library
<code>matplotlib</code>:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Make an array counting from 0 --&gt; 152, this will be our x-axis</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>x_axis <span class="op">=</span> np.arange(<span class="dv">0</span>, single_vox.shape[<span class="dv">0</span>])</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co"># Plot our x and y data, the 'k' just specifies the line color to be black</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>plt.plot( x_axis, single_vox, <span class="st">'k'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co"># Label our axes</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>plt.xlabel(<span class="st">'Timepoint'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>plt.ylabel(<span class="st">'Signal Value'</span>)</span></code></pre>
</div>
<figure><img src="../fig/timeseries.png" class="img-responsive figure mx-auto d-block" alt="Example fMRI Timeseries"></figure><p>As you can see from the image above, fMRI data really is just a
signal per voxel over time!</p>
</section><section id="resampling"><h2 class="section-heading">Resampling<a class="anchor" aria-label="anchor" href="#resampling"></a>
</h2>
<hr class="half-width">
<p>Recall from our introductory exploration of neuroimaging data:</p>
<ul>
<li>T1 images are typically composed of voxels that are 1x1x1 in
dimension</li>
<li>Functional images are typically composed of voxels that are 4x4x4 in
dimension</li>
</ul>
<p>If we’d like to overlay our functional on top of our T1 (for
visualization purposes, or analyses), then we need to match the size of
the voxels!</p>
<p>Think of this like trying to overlay a 10x10 JPEG and a 20x20 JPEG on
top of each other. To get perfect overlay we need to resize (or more
accurately <em>resample</em>) our JPEGs to match!</p>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<p>Resampling is a method of interpolating in between data-points. When
we stretch an image we need to figure out what goes in the spaces that
are created via stretching - resampling does just that. In fact,
resizing any type of image is actually just resampling to new
dimensions.</p>
</div>
</div>
</div>
<p>Let’s resampling some MRI data using nilearn.</p>
<p><strong>Goal</strong>: Match the dimensions of the structural image
to that of the functional image</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Files we'll be using (Notice that we're using _space-MNI...</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co"># which means they are normalized brains)</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>T1_mni <span class="op">=</span> T1w_files[<span class="dv">0</span>]</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>T1_mni_img <span class="op">=</span> nimg.load_img(T1_mni)</span></code></pre>
</div>
<p>Let’s take a quick look at the sizes of both our functional and
structural files:</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="bu">print</span>(T1_mni_img.shape)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="bu">print</span>(func_mni_img.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(193, 229, 193)
(60, 77, 49, 152)</code></pre>
</div>
<p>Taking a look at the spatial dimensions (first three dimensions), we
can see that the number of voxels in the T1 image does not match that of
the fMRI image. This is because the fMRI data (which has less voxels) is
a <em>lower resolution image</em>. We either need to <em>upsample</em>
our fMRI image to match that of the T1 image, or we need to
<em>downsample</em> our T1 image to match that of the fMRI image.
Typically, since the fMRI data is the one we’d like to ultimately use
for analysis, we would leave it alone and downsample our T1 image. The
reason being is that <em>resampling</em> requires interpolating values
which may contaminate our data with artifacts. We don’t mind having
artifacts in our T1 data (for visualization purposes) since the fMRI
data is the one actually being analyzed.</p>
<p>Resampling in nilearn is as easy as telling it which image you want
to sample and what the target image is.</p>
<p>Structure of function:</p>
<p><code>nimg.resample_to_img(source_img,target_img,interpolation)</code></p>
<ul>
<li>
<code>source_img</code> = the image you want to sample</li>
<li>
<code>target_img</code> = the image you wish to <em>resample
to</em>
</li>
<li>
<code>interpolation</code> = the method of interpolation</li>
</ul>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout2"></a>
</h3>
<div class="callout-content">
<p>A note on <strong>interpolation</strong> nilearn supports 3 types of
interpolation, the one you’ll use depends on the type of data you’re
resampling!</p>
<ol style="list-style-type: decimal">
<li>
<strong>continuous</strong> - Interpolate but maintain some edge
features. Ideal for structural images where edges are well-defined. Uses
<span class="math inline">\(3^\\text{rd}\)</span>-order spline
interpolation.</li>
<li>
<strong>linear (default)</strong> - Interpolate uses a combination
of neighbouring voxels - will blur. Uses trilinear interpolation.</li>
<li>
<strong>nearest</strong> - matches value of closest voxel (majority
vote from neighbours). This is ideal for masks which are binary since it
will preserve the 0’s and 1’s and will not produce in-between values
(ex: 0.342). Also ideal for numeric labels where values are 0,1,2,3…
(parcellations). Uses nearest-neighbours interpolation with majority
vote.</li>
</ol>
</div>
</div>
</div>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co">#Try playing around with methods of interpolation</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="co">#options: 'linear','continuous','nearest'</span></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>resamp_t1 <span class="op">=</span> nimg.resample_to_img(source_img<span class="op">=</span>T1_mni_img,target_img<span class="op">=</span>func_mni_img,interpolation<span class="op">=</span><span class="st">'continuous'</span>)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="bu">print</span>(resamp_t1.shape)</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="bu">print</span>(func_mni_img.shape)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>nplot.plot_anat(resamp_t1)</span></code></pre>
</div>
<figure><img src="../fig/downsample_t1.png" class="img-responsive figure mx-auto d-block" alt="Downsampled T1"></figure><p>Now that we’ve explored the idea of resampling let’s do a cumulative
exercise bringing together ideas from resampling and basic image
operations.</p>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise<a class="anchor" aria-label="anchor" href="#exercise-1"></a>
</h3>
<div class="callout-content">
<p>Using <strong>Native</strong> T1 and <strong>T1w</strong> resting
state functional do the following:</p>
<ol style="list-style-type: decimal">
<li>Resample the T1 image to resting state size</li>
<li>Replace the brain in the T1 image with the first frame of the
resting state brain</li>
</ol>
<div class="section level3">
<h3 id="files-well-need">Files we’ll need<a class="anchor" aria-label="anchor" href="#files-well-need"></a>
</h3>
<div class="section level4">
<h4 id="structural-files">Structural Files<a class="anchor" aria-label="anchor" href="#structural-files"></a>
</h4>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co">#T1 image</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>ex_t1 <span class="op">=</span> nimg.load_img(T1w_files[<span class="dv">0</span>])</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co">#mask file</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>ex_t1_bm <span class="op">=</span> nimg.load_img(brainmask_files[<span class="dv">0</span>])</span></code></pre>
</div>
</div>
<div class="section level4">
<h4 id="functional-files">Functional Files<a class="anchor" aria-label="anchor" href="#functional-files"></a>
</h4>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co">#This is the pre-processed resting state data that hasn't been standardized</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>ex_func <span class="op">=</span> nimg.load_img(func_files[<span class="dv">0</span>])</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a><span class="co">#This is the associated mask for the resting state image.</span></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>ex_func_bm <span class="op">=</span> nimg.load_img(func_mask_files[<span class="dv">0</span>])</span></code></pre>
</div>
<p>The first step is to remove the brain from the T1 image so that we’re
left with a hollow skull. This can be broken down into 2 steps:</p>
<ol style="list-style-type: decimal">
<li>Invert the mask so that all 1’s become 0’s and all 0’s become
1’s</li>
</ol>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># Invert the T1 mask</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>invert_mask <span class="op">=</span> nimg.math_img(<span class="st">'??'</span>, a<span class="op">=</span>??)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>nplot.plot_anat(??)</span></code></pre>
</div>
<figure><img src="../fig/exercise_inverted_mask.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise Inverted Mask"></figure><ol start="2" style="list-style-type: decimal">
<li>Apply the mask onto the T1 image, this will effectively remove the
brain</li>
</ol>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="co"># Apply the mask onto the T1 image</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>hollow_skull <span class="op">=</span> nimg.math_img(<span class="st">"??"</span>, a<span class="op">=</span>??, b<span class="op">=</span>??)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>nplot.plot_anat(??)</span></code></pre>
</div>
<figure><img src="../fig/exercise_hollow_skull.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise Hollow Skull"></figure><p>Our brain is now missing!</p>
<p>Next we need to <em>resize</em> the hollow skull image to the
dimensions of our resting state image. This can be done using resampling
as we’ve done earlier in this episode.</p>
<p>What kind of interpolation would we need to perform here? Recall
that:</p>
<ul>
<li>
<strong>Continuous</strong>: Tries to maintain the edges of the
image</li>
<li>
<strong>Linear</strong>: Resizes the image but also blurs it a
bit</li>
<li>
<strong>Nearest</strong>: Sets values to the closest neighbouring
values</li>
</ul>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co">#Resample the T1 to the size of the functional image!</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>resamp_skull <span class="op">=</span> nimg.resample_to_img(source_img<span class="op">=</span>??,</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>                                 target_img<span class="op">=</span>??,</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>                                 interpolation<span class="op">=</span><span class="st">'??'</span>)</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>nplot.plot_anat(resamp_skull)</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a><span class="bu">print</span>(resamp_skull.shape)</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="bu">print</span>(ex_func.shape)</span></code></pre>
</div>
<figure><img src="../fig/exercise_resampled_hollow_skull.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise Resampled Hollow Skull"></figure><p>We now have a skull missing the structural T1 brain that is resized
to match the dimensions of the EPI image.</p>
<p>The final steps are to:</p>
<ol style="list-style-type: decimal">
<li>Pull the first volume from the functional image</li>
<li>Place the functional image head into the hollow skull that we’ve
created</li>
</ol>
<p>Since a functional image is 4-Dimensional, we’ll need to pull the
first volume to work with. This is because the structural image is
3-dimensional and operations will fail if we try to mix 3D and 4D
data.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co">#Let's visualize the first volume of the functional image:</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>first_vol <span class="op">=</span> ex_func.slicer[??, ??, ??, ??]</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>nplot.plot_epi(first_vol)</span></code></pre>
</div>
<figure><img src="../fig/exercise_fmri.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise fMRI"></figure><p>As shown in the figure above, the image has some “signal” outside of
the brain. In order to place this within the now brainless head we made
earlier, we need to mask out the functional MR data as well!</p>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co">#Mask the first volume using ex_func_bm</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>masked_func <span class="op">=</span> nimg.math_img(<span class="st">'??'</span>, a<span class="op">=</span>??, b<span class="op">=</span>??)</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>nplot.plot_epi(masked_func)</span></code></pre>
</div>
<figure><img src="../fig/exercise_masked_fmri.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise Masked fMRI"></figure><p>The final step is to stick this data into the head of the T1 data.
Since the hole in the T1 data is represented as <span class="math inline">\(0\)</span>’s. We can add the two images together
to place the functional data into the void:</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="co">#Now overlay the functional image on top of the anatomical</span></span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>combined_img <span class="op">=</span> nimg.math_img(??)</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>nplot.plot_anat(combined_img)</span></code></pre>
</div>
<figure><img src="../fig/exercise_complete.png" class="img-responsive figure mx-auto d-block" alt="Episode 04 Exercise Complete"></figure>
</div>
</div>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="co"># Invert the mask</span></span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>invert_mask <span class="op">=</span> nimg.math_img(<span class="st">'1-a'</span>, a<span class="op">=</span>ex_t1_bm)</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>nplot.plot_anat(invert_mask)</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a><span class="co"># Apply the mask onto the T1 image</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>hollow_skull <span class="op">=</span> nimg.math_img(<span class="st">"a*b"</span>, a<span class="op">=</span>ex_t1, b<span class="op">=</span>invert_mask)</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>nplot.plot_anat(hollow_skull)</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a><span class="co">#Resample the T1 to the size of the functional image!</span></span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a>resamp_skull <span class="op">=</span> nimg.resample_to_img(source_img<span class="op">=</span>hollow_skull,</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>                                 target_img<span class="op">=</span>ex_func,</span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a>                                 interpolation<span class="op">=</span><span class="st">'continuous'</span>)</span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a>nplot.plot_anat(resamp_skull)</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a><span class="bu">print</span>(resamp_skull.shape)</span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a><span class="bu">print</span>(ex_func.shape)</span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a><span class="co">#Let's visualize the first volume of the functional image:</span></span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a>first_vol <span class="op">=</span> ex_func.slicer[:,:,:,<span class="dv">0</span>]</span>
<span id="cb26-19"><a href="#cb26-19" tabindex="-1"></a>nplot.plot_epi(first_vol)</span>
<span id="cb26-20"><a href="#cb26-20" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" tabindex="-1"></a>masked_func <span class="op">=</span> nimg.math_img(<span class="st">'a*b'</span>, a<span class="op">=</span>first_vol, b<span class="op">=</span>ex_func_bm)</span>
<span id="cb26-22"><a href="#cb26-22" tabindex="-1"></a>nplot.plot_epi(masked_func)</span>
<span id="cb26-23"><a href="#cb26-23" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" tabindex="-1"></a><span class="co">#Now overlay the functional image on top of the anatomical</span></span>
<span id="cb26-25"><a href="#cb26-25" tabindex="-1"></a>combined_img <span class="op">=</span> nimg.math_img(<span class="st">'a+b'</span>,</span>
<span id="cb26-26"><a href="#cb26-26" tabindex="-1"></a>                             a<span class="op">=</span>resamp_skull, </span>
<span id="cb26-27"><a href="#cb26-27" tabindex="-1"></a>                             b<span class="op">=</span>masked_func)</span>
<span id="cb26-28"><a href="#cb26-28" tabindex="-1"></a>nplot.plot_anat(combined_img)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>This doesn’t actually achieve anything useful in practice. However it
has hopefully served to get you more comfortable with the idea of
resampling and performing manipulations on MRI data!</p>
<p>In this section we explored functional MR imaging. Specifically we
covered:</p>
<ol style="list-style-type: decimal">
<li>How the data in a fMRI scan is organized - with the additional
dimension of timepoints</li>
<li>How we can integrate functional MR images to our structural image
using resampling</li>
<li>How we can just as easily manipulate functional images using
<code>nilearn</code>
</li>
</ol>
<p>Now that we’ve covered all the basics, it’s time to start working on
data processing using the tools that we’ve picked up.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>fMRI data is represented by spatial (x,y,z) and temporal (t)
dimensions, totalling 4 dimensions</li>
<li>fMRI data is at a lower resolution than structural data. To be able
to combine data requires resampling your data</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-05-data-cleaning-with-nilearn"><p>Content from <a href="05-data-cleaning-with-nilearn.html">Cleaning Confounders in your Data with Nilearn</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/05-data-cleaning-with-nilearn.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we clean the data so that it more closely reflects BOLD
instead of artifacts</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the motivation behind confound/nuisance regression</li>
<li>Learn how to implement cleaning using nilearn and fmriprep</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="introduction"><h2 class="section-heading">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p><strong>Movement is the enemy of Neuroimagers</strong></p>
<p>Movement is an important problem that we need to deal with in our
data. In resting state fMRI movement can induce false correlations
between brain regions leading to inaccurate conclusions about brain
connectivity. However, there is a unique problem that resting state fMRI
faces when dealing with movement:</p>
<ul>
<li>In resting state fMRI, <em>we don’t actually ever see the true
underlying BOLD signal</em>.</li>
</ul>
<p>This is un-like task-based fMRI where there is an expectation that
we’ll observe a BOLD signal upon event onset - we have some information
about what the true underlying BOLD signal might look like. In order to
deal with the problem of movement in resting state fMRI we need to
<em>model</em> our fMRI signal to be comprised of <strong>true brain
signal</strong> and <strong>motion (confounder) signals</strong>. We can
make estimates about how motion can influence our data then remove it
from the recorded signal; the leftover signal is what we estimate the
BOLD signal to be.</p>
<p>This process of removing motion-based artifacts from our data is
called <strong>confound regression</strong>, which is essentially
fitting a linear model using motion estimates as regressors then
subtracting it out from the signal. Hopefully in this process we get a
<em>closer estimate</em> of what the actual brain-induced BOLD signal
looks like.</p>
<p>In this section we’ll implement confound regression for resting-state
data using nilearn’s high-level functionality.</p>
</section><section id="setting-up"><h2 class="section-heading">Setting up<a class="anchor" aria-label="anchor" href="#setting-up"></a>
</h2>
<hr class="half-width">
<p>Let’s load in some modules as we’ve done before</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> nimg</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> nplot</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> nibabel <span class="im">as</span> nib</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code></pre>
</div>
<div class="section level3">
<h3 id="setting-up-our-motion-estimates">Setting up our Motion Estimates<a class="anchor" aria-label="anchor" href="#setting-up-our-motion-estimates"></a>
</h3>
<p>The beauty of FMRIPREP is that it estimates a number of
motion-related signals for you and outputs it into:</p>
<p><strong>sub-xxxx_task-xxxx_desc-confounds_timeseries.tsv</strong></p>
<p>This is basically a spreadsheet that has columns related to each
motion estimate type and rows for timepoints. We can view these using a
language-python package called <code>pandas</code>.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre>
</div>
<p>Let’s pick an fMRI file to clean and pull out the confound tsv that
FMRIPREP computed for us:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> bids  <span class="co"># assuming pip install pybids was covered earlier</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>sub <span class="op">=</span> <span class="st">'10788'</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>fmriprep_dir <span class="op">=</span> <span class="st">'../data/ds000030/derivatives/fmriprep/'</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>layout <span class="op">=</span> bids.BIDSLayout(fmriprep_dir,validate<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>                        config<span class="op">=</span>[<span class="st">'bids'</span>,<span class="st">'derivatives'</span>])</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>func_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>                        datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>                        desc<span class="op">=</span><span class="st">'preproc'</span>,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>                        space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>                        extension<span class="op">=</span><span class="st">'nii.gz'</span>,</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>                       return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>mask_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>                        datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>                        desc<span class="op">=</span><span class="st">'brain'</span>,</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>                        suffix<span class="op">=</span><span class="st">'mask'</span>,</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>                        space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>                        extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>                       return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>confound_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>                            datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>                            desc<span class="op">=</span><span class="st">'confounds'</span>,</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>                           extension<span class="op">=</span><span class="st">"tsv"</span>,</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>                           return_type<span class="op">=</span><span class="st">'file'</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>func_file <span class="op">=</span> func_files[<span class="dv">0</span>]</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>mask_file <span class="op">=</span> mask_files[<span class="dv">0</span>]</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>confound_file <span class="op">=</span> confound_files[<span class="dv">0</span>]</span></code></pre>
</div>
<p>Using <code>pandas</code> we can read in the confounds.tsv file as a
spreadsheet and display some rows:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co">#Delimiter is \t --&gt; tsv is a tab-separated spreadsheet</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>confound_df <span class="op">=</span> pd.read_csv(confound_file, delimiter<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Read </span><span class="sc">{</span><span class="bu">len</span>(confound_df.columns)<span class="sc">}</span><span class="ss"> confounder items, each </span><span class="sc">{</span><span class="bu">len</span>(confound_df)<span class="sc">}</span><span class="ss"> TRs."</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="bu">print</span>(confound_df.head)</span></code></pre>
</div>
<p>Each column in this DataFrame <code>confound_df</code> represents a
specific confound variable that is either estimated directly from head
motion during the functional scan or other noise characteristics that
may capture noise (non grey-matter signal for example). Each row
represents values from a TR/sample. So the number of rows in your
<code>confound_df</code> should match the number of TRs you have in the
functional MR data.</p>
<div id="picking-your-confounds" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="picking-your-confounds" class="callout-inner">
<h3 class="callout-title">Picking your Confounds<a class="anchor" aria-label="anchor" href="#picking-your-confounds"></a>
</h3>
<div class="callout-content">
<p>The choice of which confounds to use in functional imaging analysis
is a source of large debate. We recommend that you check out these
sources for a start:</p>
<ol style="list-style-type: decimal">
<li><a href="https://www.sciencedirect.com/science/article/pii/S1053811917302288#f0005" class="external-link">https://www.sciencedirect.com/science/article/pii/S1053811917302288#f0005</a></li>
<li>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811917302288" class="external-link">https://www.sciencedirect.com/science/article/pii/S1053811917302288</a>
For now we’re going to replicate the pre-processing (mostly) from the
seminal Yeo1000 17-networks paper: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21653723" class="external-link">https://www.ncbi.nlm.nih.gov/pubmed/21653723</a>
</li>
</ol>
</div>
</div>
</div>
<hr>
<div class="section level4">
<h4 id="the-yeo-2011-pre-processing-schema">The Yeo 2011 Pre-processing schema<a class="anchor" aria-label="anchor" href="#the-yeo-2011-pre-processing-schema"></a>
</h4>
<div class="section level5">
<h5 id="confound-regressors">Confound regressors<a class="anchor" aria-label="anchor" href="#confound-regressors"></a>
</h5>
<ol style="list-style-type: decimal">
<li>6 motion parameters (trans_x, trans_y, trans_z, rot_x, rot_y,
rot_z)</li>
<li>Global signal (global_signal)</li>
<li>Cerebral spinal fluid signal (csf)</li>
<li>White matter signal (white_matter)</li>
</ol>
<p>This is a total of 9 base confound regressor variables. Finally we
add temporal derivatives of each of these signals as well (1 temporal
derivative for each), the result is 18 confound regressors.</p>
<hr>
<p><strong>Temporal Derivatives</strong> are the changes in values
across 2 consecutive samples. It represents change in signal over time.
For example, when dealing with the confound variable “X”, which
represents motion along the “trans_x” direction, the temporal derivative
represents <em>velocity in the X direction</em>.</p>
<hr>
</div>
<div class="section level5">
<h5 id="lowhigh-pass-filtering">Low/High pass filtering<a class="anchor" aria-label="anchor" href="#lowhigh-pass-filtering"></a>
</h5>
<ol style="list-style-type: decimal">
<li>Low pass filtering cutoff: 0.08</li>
<li>High pass filtering cutoff: 0.009</li>
</ol>
<p>Low pass filters out high frequency signals from our data. fMRI
signals are slow evolving processes, any high frequency signals are
likely due to noise High pass filters out any very low frequency signals
(below 0.009Hz), which may be due to intrinsic scanner instabilities</p>
</div>
<div class="section level5">
<h5 id="drop-dummy-trs">Drop dummy TRs<a class="anchor" aria-label="anchor" href="#drop-dummy-trs"></a>
</h5>
<p>During the initial stages of a functional scan there is a strong
signal decay artifact, thus the first 4ish or so TRs are very high
intensity signals that don’t reflect the rest of the scan. Therefore we
drop these timepoints.</p>
</div>
<div class="section level5">
<h5 id="censoring-interpolation-leaving-out">Censoring + Interpolation (leaving out)<a class="anchor" aria-label="anchor" href="#censoring-interpolation-leaving-out"></a>
</h5>
<p>Censoring involves removal and interpolation of high-movement frames
from the fMRI data. Interpolation is typically done using sophisticated
algorithms much like <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3849338/" class="external-link">Power et
al. 2014</a>.</p>
<p><strong>We won’t be using censoring + interpolation since its fairly
complicated and would take up too much time</strong></p>
<hr>
</div>
</div>
<div class="section level4">
<h4 id="setting-up-confound-variables-for-regression">Setting up Confound variables for regression<a class="anchor" aria-label="anchor" href="#setting-up-confound-variables-for-regression"></a>
</h4>
<div class="section level5">
<h5 id="computing-temporal-derivatives-for-confound-variables">Computing temporal derivatives for confound variables<a class="anchor" aria-label="anchor" href="#computing-temporal-derivatives-for-confound-variables"></a>
</h5>
<p>First we’ll select our confound variables from our dataframe. You can
do this by specifying a list of confounds, then using that list to pull
out the associated columns</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Select confounds</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>confound_vars <span class="op">=</span> [<span class="st">'trans_x'</span>,<span class="st">'trans_y'</span>,<span class="st">'trans_z'</span>,</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>                 <span class="st">'rot_x'</span>,<span class="st">'rot_y'</span>,<span class="st">'rot_z'</span>,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>                 <span class="st">'global_signal'</span>,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>                 <span class="st">'csf'</span>, <span class="st">'white_matter'</span>]</span></code></pre>
</div>
<p>Next we need to get derivatives for each of these columns. Luckily
fMRIPrep provides this for us. Derivative columns are denoted as the
following:</p>
<ul>
<li>{NAME_OF_COLUMN}_derivative1</li>
</ul>
<p>Since typing is alot of work, we’ll use a for-loop instead to pick
the derivatives for our <code>confound_vars</code>:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Get derivative column names</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>derivative_columns <span class="op">=</span> [<span class="st">'</span><span class="sc">{}</span><span class="st">_derivative1'</span>.<span class="bu">format</span>(c) <span class="cf">for</span> c</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>                     <span class="kw">in</span> confound_vars]</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="bu">print</span>(derivative_columns)</span></code></pre>
</div>
<p>Now we’ll join these two lists together:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>final_confounds <span class="op">=</span> confound_vars <span class="op">+</span> derivative_columns</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a><span class="bu">print</span>(final_confounds)</span></code></pre>
</div>
<p>Finally we’ll use this list to pick columns from our confounds
table</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>confound_df <span class="op">=</span> confound_df[final_confounds]</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>confound_df.head()</span></code></pre>
</div>
<div id="what-the-nan" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="what-the-nan" class="callout-inner">
<h3 class="callout-title">What the NaN???<a class="anchor" aria-label="anchor" href="#what-the-nan"></a>
</h3>
<div class="callout-content">
<p>As you might have noticed, we have NaN’s in our confound dataframe.
This happens because there is no prior value to the first index to take
a difference with, but this isn’t a problem since we’re going to be
dropping 4 timepoints from our data and confounders anyway!</p>
</div>
</div>
</div>
</div>
<div class="section level5">
<h5 id="dummy-tr-drop">Dummy TR Drop<a class="anchor" aria-label="anchor" href="#dummy-tr-drop"></a>
</h5>
<p>Now we’ll implement our <strong>Dummy TR Drop</strong>. Remember this
means that we are removing the first 4 timepoints from our functional
image (we’ll also have to do this for our first 4 confound
timepoints!):</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co">#First we'll load in our data and check the shape</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>raw_func_img <span class="op">=</span> nimg.load_img(func_file)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>raw_func_img.shape</span></code></pre>
</div>
<p>Recall that the fourth dimension represents frames/TRs(timepoints).
We want to drop the first four timepoints entirely, to do so we use
nibabel’s slicer feature. We’ll also drop the first 4 confound variable
timepoints to match the functional scan</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>func_img <span class="op">=</span> raw_func_img.slicer[:,:,:,<span class="dv">4</span>:]</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>func_img.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(65, 77, 49, 148)</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co">#Drop confound dummy TRs</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>drop_confound_df <span class="op">=</span> confound_df.loc[<span class="dv">4</span>:]</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="bu">print</span>(drop_confound_df.shape) <span class="co">#number of rows should match that of the functional image</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>drop_confound_df.head()</span></code></pre>
</div>
</div>
</div>
<div class="section level4">
<h4 id="applying-confound-regression">Applying confound regression<a class="anchor" aria-label="anchor" href="#applying-confound-regression"></a>
</h4>
<p>Now we’d like to clean our data of our selected confound variables.
There are two ways to go about this:</p>
<ol style="list-style-type: decimal">
<li>If you have nilearn version 0.5.0 or higher use
<code>nilearn.image.clean_img(image,confounds,…)</code>
</li>
<li>If you want full control over specific parts of the image you’re
cleaning use <code>nilearn.signal.clean(signals,confounds,…)</code>
</li>
</ol>
<p>The first method is probably most practical and can be done in one
line given what we’ve already set-up. However, in cases of very large
datasets (HCP-style), the second method might be preferable for
optimizing memory usage.</p>
<p>First note that both methods take an argument <code>confounds</code>.
This is a matrix:</p>
<figure><img src="../fig/matrix.png" class="img-responsive figure mx-auto d-block" alt="Confounds Matrix"></figure><p>Therefore our goal is to take our confound matrix and work it into a
matrix of the form above. The end goal is a matrix with 147 rows, and
columns matching the number of confound variables (9x2=18)</p>
<p>Luckily this is a one-liner!</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>confounds_matrix <span class="op">=</span> drop_confound_df.values</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co">#Confirm matrix size is correct</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>confounds_matrix.shape</span></code></pre>
</div>
<p>Let’s clean our image!</p>
</div>
</div>
<div class="section level3">
<h3 id="using-nilearn-image-clean_img">Using <code>nilearn.image.clean_img</code>
<a class="anchor" aria-label="anchor" href="#using-nilearn-image-clean_img"></a>
</h3>
<p>First we’ll describe a couple of this function’s important arguments.
Any argument enclosed in [arg] is optional</p>
<p><code>nilearn.image.clean_img(image,confounds,[low_pass],[high_pass],[t_r],[mask_img],[detrend],[standardize])</code></p>
<p><strong>Required</strong>:</p>
<ul>
<li>
<code>image</code>: The functional image (<code> func_img
</code>)</li>
<li>
<code>confounds</code>: The confound matrix (<code> confounds
</code>)</li>
</ul>
<p><strong>Optional</strong>:</p>
<ul>
<li>
<code>low_pass</code>: A low pass filter cut-off</li>
<li>
<code>high_pass</code> A high pass filter cut-off</li>
<li>
<code>t_r</code>: This is required if using low/high pass, the
repetition time of acquisition (imaging metadata)</li>
<li>
<code>mask_img</code> Apply a mask when performing confound
regression, will speed up regression</li>
<li>
<code>detrend</code>: Remove drift from the data (useful for
removing scanner instability artifacts) [default=True]</li>
<li>
<code>standardize</code>: Set mean to 0, and variance to 1 –&gt;
sets up data for statistical analysis [default=True]</li>
</ul>
<hr>
<p><strong>What we’re using</strong>:</p>
<p>The Repetition Time of our data is 2 seconds, in addition since we’re
replicating (mostly) Yeo 2011’s analysis:</p>
<ul>
<li>high_pass = 0.009</li>
<li>low_pass = 0.08</li>
<li>detrend = True</li>
<li>standardize = True</li>
</ul>
<p>In addition we’ll use a mask of our MNI transformed functional image
(<code> mask </code>) to speed up cleaning</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co">#Set some constants</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>high_pass<span class="op">=</span> <span class="fl">0.009</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>low_pass <span class="op">=</span> <span class="fl">0.08</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>t_r <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co">#Clean!</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>clean_img <span class="op">=</span> nimg.clean_img(func_img,confounds<span class="op">=</span>confounds_matrix,detrend<span class="op">=</span><span class="va">True</span>,standardize<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>                         low_pass<span class="op">=</span>low_pass,high_pass<span class="op">=</span>high_pass,t_r<span class="op">=</span>t_r, mask_img<span class="op">=</span>mask_file)</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co">#Let's visualize our result! Doesn't really tell us much, but that's the data we're using for analysis!</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>nplot.plot_epi(clean_img.slicer[:,:,:,<span class="dv">50</span>])</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>before_figure <span class="op">=</span> nplot.plot_carpet(clean_img, mask, t_r<span class="op">=</span>t_r)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>after_figure <span class="op">=</span> nplot.plot_carpet(func_img, mask, t_r<span class="op">=</span>t_r)</span></code></pre>
</div>
<div class="section level4">
<h4 id="done">Done!<a class="anchor" aria-label="anchor" href="#done"></a>
</h4>
<p>Hopefully by now you’ve learned what confound regression is, and how
to perform it in nilearn using 2 different methods. We’d like to note
that there are many more methods to perform confound regression
(simultaneous signal extraction + confound regression for example) but
all those methods fundamentally rely on what you’ve done here.</p>
<p>In addition, performing confound regression on <em>functional
volumes</em>, is also not the only way to do data cleaning. More modern
methods involve applying confound regression on <em>functional
surfaces</em>, however, those methods are too advanced for an
introductory course to functional data analysis and involve tools
outside of python.</p>
<p>If you’re interested in surface-based analysis we recommend that you
check out the following sources:</p>
<ol style="list-style-type: decimal">
<li><a href="https://edickie.github.io/ciftify/#/" class="external-link">https://edickie.github.io/ciftify/#/</a></li>
<li><a href="https://www.humanconnectome.org/software/connectome-workbench" class="external-link">https://www.humanconnectome.org/software/connectome-workbench</a></li>
<li><a href="https://www.ncbi.nlm.nih.gov/pubmed/23668970" class="external-link">The minimal
preprocessing pipelines for the Human Connectome Project</a></li>
</ol>
<hr>
<p>The section below is <strong>optional</strong> and is a more advanced
dive into the underlying mechanics of how <code>nilearn.clean_img</code>
works:</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Nuisance regression is an attempt to make sure your results aren’t
driven by non-brain signals</li>
<li>With resting state, we don’t actually ever know the true signal - we
can only attempt to estimate it</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section></section><section id="aio-06-apply-a-parcellation"><p>Content from <a href="06-apply-a-parcellation.html">Applying Parcellations to Resting State Data</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/06-apply-a-parcellation.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 40 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we reduce amount of noise-related variance in our data?</li>
<li>How can we frame our data as a set of meaningful features?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Learn about the utility of parcellations as a data dimensionalty
reduction tool</li>
<li>Understand what the tradeoffs are when using parcellations to
analyze your data</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="introduction"><h2 class="section-heading">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width"></section><section id="what-is-a-brain-atlas-or-parcellation"><h2 class="section-heading">What is a Brain Atlas or Parcellation?<a class="anchor" aria-label="anchor" href="#what-is-a-brain-atlas-or-parcellation"></a>
</h2>
<hr class="half-width">
<p>A brain atlas/parcellation is a voxel-based labelling of your data
into “structural or functional units”. In a parcellation schema each
voxel is assigned a numeric (integer) label corresponding to the
structural/functional unit that the particular voxel is thought to
belong to based on some criteria. You might wonder why someone would
simply <em>average together a bunch of voxels</em> in a way that would
reduce the richness of the data. This boils down to a few problems
inherit to functional brain imaging:</p>
<ol style="list-style-type: decimal">
<li>Resting state data is noisy, averaging groups of “similar” voxels
reduces the effect of random noise effects</li>
<li>Provide an interpretative framework to functional imaging data. For
example one parcellation group might be defined as the Default Mode
Network which is thought to be functionally significant. So averaging
voxels together belonging to the Default Mode Network provides an
average estimate of the Default Mode Network signal. In addition the
discovery of the Default Mode Network has yielded important insights
into the organizational principles of the brain.</li>
<li>Limit the number of statistical tests thereby reducing potential
Type I errors without resorting to strong statistical correction
techniques that might reduce statistical power.</li>
<li>A simpler way to visualize your data, instead of 40x40x40=6400 data
points, you might have 17 or up to 200; this is still significantly less
data to deal with!</li>
</ol></section><section id="applying-a-parcellation-to-your-data"><h2 class="section-heading">Applying a Parcellation to your Data<a class="anchor" aria-label="anchor" href="#applying-a-parcellation-to-your-data"></a>
</h2>
<hr class="half-width">
<p>Since the parcellation of a brain is defined (currently) by spatial
locations, application of an parcellation to fMRI data only concerns the
first 3 dimensions; the last dimension (time) is retained. Thus a
parcellation assigns every voxel (x,y,z) to a particular parcel ID (an
integer).</p>
<p>Nilearn supports a large selection of different atlases that can be
found <a href="https://nilearn.github.io/modules/reference.html#module-nilearn.datasets" class="external-link">here</a>.
For information about how to select which parcellation to use for
analysis of your data we refer you to Arslan et al. 2018.</p>
<div class="section level3">
<h3 id="retrieving-the-atlas">Retrieving the Atlas<a class="anchor" aria-label="anchor" href="#retrieving-the-atlas"></a>
</h3>
<p>For this tutorial we’ll be using a set of parcellation from <a href="link">Yeo et al. 2011</a>. This atlas was generated from fMRI data
from 1000 healthy control participants.</p>
<p>First we’ll load in our packages as usual:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> datasets</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> nimg</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> nplot</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code></pre>
</div>
<p>To retrieve the Yeo atlas we’ll use the <code>fetch_atlas_*</code>
family of functions provided for by nilearn.datasets and download it
into a local directory:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>parcel_dir <span class="op">=</span> <span class="st">'../resources/rois/'</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>atlas_yeo_2011 <span class="op">=</span> datasets.fetch_atlas_yeo_2011(parcel_dir)</span></code></pre>
</div>
<p>The method <code>datasets.fetch_atlas_yeo_2011()</code> returns a
<code>dict</code> object. Examining the keys of the dictionary yields
the following:</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>atlas_yeo_2011.keys()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>output</span></code></pre>
</div>
<p>Each of the values associated with a key in
<code>atlas_yeo_2011</code> is a <code>.nii.gz</code> image which
contains a 3D NIFTI volume with a label for a given (x,y,z) voxel. Since
these images are 3D volumes (sort of like structural images), we can
view them using nilearn’s plotting utilities:</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co">#Define where to slice the image</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>cut_coords(<span class="dv">8</span>, <span class="op">-</span><span class="dv">4</span>, <span class="dv">9</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co">#Show a colorbar</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>colorbar<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#Color scheme to show when viewing image</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>cmap<span class="op">=</span><span class="st">'Paired'</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#Plot all parcellation schemas referred to by atlas_yeo_2011</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>nplot.plot_roi(atlas_yeo_2011[<span class="st">'thin_7'</span>], cut_coords<span class="op">=</span>cut_coords, colorbar<span class="op">=</span>colorbar, cmap<span class="op">=</span>cmap, title<span class="op">=</span><span class="st">'thin_7'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>nplot.plot_roi(atlas_yeo_2011[<span class="st">'thin_17'</span>], cut_coords<span class="op">=</span>cut_coords, colorbar<span class="op">=</span>colorbar, cmap<span class="op">=</span>cmap, title<span class="op">=</span><span class="st">'thin_17'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>nplot.plot_roi(atlas_yeo_2011[<span class="st">'thick_7'</span>], cut_coords<span class="op">=</span>cut_coords, colorbar<span class="op">=</span>colorbar, cmap<span class="op">=</span>cmap, title<span class="op">=</span><span class="st">'thick_7'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>nplot.plot_roi(atlas_yeo_2011[<span class="st">'thick_17'</span>], cut_coords<span class="op">=</span>cut_coords, colorbar<span class="op">=</span>colorbar, cmap<span class="op">=</span>cmap, title<span class="op">=</span><span class="st">'thick_17'</span>)</span></code></pre>
</div>
<p><img src="../fig/thin_7.png" class="img-responsive figure" alt="Yeo Thin 7"><img src="../fig/thin_17.png" class="img-responsive figure" alt="Yeo Thin 17"><img src="../fig/thick_7.png" class="img-responsive figure" alt="Yeo Thick 7"><img src="../fig/thick_17.png" class="img-responsive figure" alt="Yeo Thick 17"></p>
<p>You’ll notice that the colour bar on the right shows the number of
labels in each atlas and which colour corresponds to which network</p>
<p>The 7 and 17 network parcellations correspond to the two most stable
clustering solutions from the algorithm used by the authors. The
thin/thick designation refer to how strict the voxel inclusion is (thick
might include white matter/CSF, thin might exclude some regions of grey
matter due to partial voluming effects).</p>
<p>For simplicity we’ll use the thick_7 variation which includes the
following networks:</p>
<ol style="list-style-type: decimal">
<li>Visual</li>
<li>Somatosensory</li>
<li>Dorsal Attention</li>
<li>Ventral Attention</li>
<li>Limbic</li>
<li>Frontoparietal</li>
<li>Default</li>
</ol>
<p>The parcel areas labelled with 0 are background voxels not associated
with a particular network.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>atlas_yeo <span class="op">=</span> atlas_yeo_2011[<span class="st">'thick_7'</span>]</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="spatial-separation-of-network">Spatial Separation of Network<a class="anchor" aria-label="anchor" href="#spatial-separation-of-network"></a>
</h3>
<p>A key feature of the Yeo2011 networks is that they are <em>spatially
distributed</em>, meaning that the locations of two voxels in the same
network need not be part of the same region. However, there could be
some cases in which you might want to examine voxels belonging to a
network within a particular region. To do this, we can separate parcels
belonging to the same network based on spatial continuity. If there is a
gap between two sets of voxels belonging to the same parcel group, we
can assign new labels to separate them out. Nilearn has a feature to
handle this:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> nilearn.regions <span class="im">import</span> connected_label_regions</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>region_labels <span class="op">=</span> connected_label_regions(atlas_yeo)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>nplot.plot_roi(region_labels,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>			cut_coords<span class="op">=</span>(<span class="op">-</span><span class="dv">20</span>,<span class="op">-</span><span class="dv">10</span>,<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">60</span>,<span class="dv">70</span>),</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>			display_mode<span class="op">=</span><span class="st">'z'</span>,</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>			colorbar<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>			cmap<span class="op">=</span><span class="st">'Paired'</span>,</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>			title<span class="op">=</span><span class="st">'Relabeled Yeo Atlas'</span>)</span></code></pre>
</div>
<figure><img src="../fig/yeo_sep.png" class="img-responsive figure mx-auto d-block" alt="Separated Yeo Labels"></figure>
</div>
<div class="section level3">
<h3 id="resampling-the-atlas">Resampling the Atlas<a class="anchor" aria-label="anchor" href="#resampling-the-atlas"></a>
</h3>
<p>Let’s store the separated version of the atlas into a NIFTI file so
that we can work with it later:</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>region_labels.to_filename(<span class="st">'../resources/rois/yeo_2011/Yeo_JNeurophysiol11_MNI152/relabeled_yeo_atlas.nii.gz'</span>)</span></code></pre>
</div>
<div id="resampling-exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="resampling-exercise" class="callout-inner">
<h3 class="callout-title">Resampling Exercise<a class="anchor" aria-label="anchor" href="#resampling-exercise"></a>
</h3>
<div class="callout-content">
<p>Our goal is to match the parcellation atlas dimensions to our
functional file so that we can use it to extract the mean time series of
each parcel region. Using <code>Nilearn</code>’s resampling capabilities
match the dimensions of the atlas file to the functional file First
let’s pick our functional file. Atlases are typically defined in
standard space so we will use the MNI152NLin2009cAsym version of the
functional file:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>func_file <span class="op">=</span> <span class="st">'../data/ds000030/derivatives/fmriprep/sub-10788/func/sub-10788_task-rest_bold_space-MNI152NLin2009cAsym_preproc.nii.gz'</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>func_img <span class="op">=</span> nib.load(func_file)</span></code></pre>
</div>
<p>First examine the size of both files, if they match we are done:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Size of functional image:'</span>, func_img.shape)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Size of atlas image:'</span>, ??)</span></code></pre>
</div>
<p>Looks like they don’t match. To resolve this, we can use
<code>nimg.resample_to_img</code> to resize the <em>atlas image</em> to
match that of the <em>functional image</em>. Think about what kind of
interpolation we’d like to use. Recall that the atlas contains integer
values (i.e 0, 1, 2, 3,…), we <em>do not want any in-between
values!</em></p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>resampled_yeo <span class="op">=</span> nimg.resample_to_img(??, ??, interpolation <span class="op">=</span> <span class="st">'??'</span>)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># Print dimensions of functional image and atlas image</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of functional image:"</span>, func_img.shape)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Size of atlas image:"</span>, region_labels.shape)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>resampled_yeo <span class="op">=</span> nimg.resample_to_img(region_labels, func_img, interpolation <span class="op">=</span> <span class="st">'nearest'</span>)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Let’s see what the resampled atlas looks like overlayed on a slice of
our NifTI file</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Note that we're pulling a random timepoint from the fMRI data</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>nplot.plot_roi(resampled_yeo, func_img.slicer[:, :, :, <span class="dv">54</span>])</span></code></pre>
</div>
<figure><img src="../fig/resampled_yeo.png" class="img-responsive figure mx-auto d-block" alt="Episode 06 Exercise Resampled Yeo Labels"></figure>
</div>
</section><section id="visualizing-rois"><h2 class="section-heading">Visualizing ROIs<a class="anchor" aria-label="anchor" href="#visualizing-rois"></a>
</h2>
<hr class="half-width">
<p>For the next section, we’ll be performing an analysis using the Yeo
parcellation on our functional data. Specifically, we’ll be using two
ROIs: 44 and 46.</p>
<blockquote>
<h2 id="exercise">Exercise</h2>
</blockquote>
<p>Visualize ROIs 44 and 46 in the Yeo atlas. We’ll be looking at these
2 ROIs in more detail during our analysis</p>
<div id="challenge2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Challenge<a class="anchor" aria-label="anchor" href="#challenge2"></a>
</h3>
<div class="callout-content">
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>roi <span class="op">=</span> <span class="dv">44</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="co"># Make a mask for ROI 44</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>roi_mask_44 <span class="op">=</span> nimg.math_img(<span class="st">'a == ??'</span>, a<span class="op">=</span>resampled_yeo)  </span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co"># Visualize ROI</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>nplot.plot_roi(??)</span></code></pre>
</div>
<figure><img src="../fig/roi_44.png" class="img-responsive figure mx-auto d-block" alt="Episode 06 Exercise Yeo ROI 44"></figure><div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>roi <span class="op">=</span> <span class="dv">46</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co"># Make a mask for ROI 44</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>roi_mask_46 <span class="op">=</span> nimg.math_img(??)  </span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co"># Visualize ROI</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>??</span></code></pre>
</div>
<figure><img src="../fig/roi_46.png" class="img-responsive figure mx-auto d-block" alt="Episode 06 Exercise Yeo ROI 46"></figure>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">Show me the solution</h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Make a mask for ROI 44</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>roi_mask <span class="op">=</span> nimg.math_img(<span class="st">'a == 44'</span>, a<span class="op">=</span>resampled_yeo)  </span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co"># Visualize ROI</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>nplot.plot_roi(masked_resamp_yeo)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="co"># Make a mask for ROI 44</span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>roi_mask <span class="op">=</span> nimg.math_img(<span class="st">'a == 46'</span>, a<span class="op">=</span>resampled_yeo)  </span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co"># Visualize ROI</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>nplot.plot_roi(masked_resamp_yeo)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>Parcellations group voxels based on criteria such as similarities,
orthogonality or some other criteria</li>
<li>Nilearn stores several standard parcellations that can be applied to
your data</li>
<li>Parcellations are defined by assigning each voxel a parcel
‘membership’ value telling you which group the parcel belongs to</li>
<li>Parcellations provide an interpretative framework for understanding
resting state data. But beware, some of the techniques used to form
parcellations may not represent actual brain functional units!</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-07-functional-connectivity-analysis"><p>Content from <a href="07-functional-connectivity-analysis.html">Functional Connectivity Analysis</a></p>
<hr>
<p>Last updated on 2024-02-17 |
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/episodes/07-functional-connectivity-analysis.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can we estimate brain functional connectivity patterns from
resting state data?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Use parcellations to reduce fMRI noise and speed up computation of
functional connectivity</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="introduction"><h2 class="section-heading">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<hr class="half-width">
<p>Now we have an idea of three important components to analyzing
neuroimaging data:</p>
<ol style="list-style-type: decimal">
<li>Data manipulation</li>
<li>Cleaning and confound regression</li>
<li>Parcellation and signal extraction</li>
</ol>
<p>In this notebook the goal is to integrate these 3 basic components
and perform a full analysis of group data using <strong>Intranetwork
Functional Connectivity (FC)</strong>.</p>
<p>Intranetwork functional connectivity is essentially a result of
performing correlational analysis on mean signals extracted from two
ROIs. Using this method we can examine how well certain resting state
networks, such as the <strong>Default Mode Network (DMN)</strong>, are
synchronized across spatially distinct regions.</p>
<p>ROI-based correlational analysis forms the basis of many more
sophisticated kinds of functional imaging analysis.</p>
</section><section id="using-nilearns-high-level-functionality-to-compute-correlation-matrices"><h2 class="section-heading">Using Nilearn’s High-level functionality to compute correlation
matrices<a class="anchor" aria-label="anchor" href="#using-nilearns-high-level-functionality-to-compute-correlation-matrices"></a>
</h2>
<hr class="half-width">
<p>Nilearn has a built in function for extracting timeseries from
functional files and doing all the extra signal processing at the same
time. Let’s walk through how this is done</p>
<p>First we’ll grab our imports as usual</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> image <span class="im">as</span> nimg</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> plotting <span class="im">as</span> nplot</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> bids <span class="im">import</span> BIDSLayout</span></code></pre>
</div>
<p>Let’s grab the data that we want to perform our connectivity analysis
on using PyBIDS:</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co">#Use PyBIDS to parse BIDS data structure</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>layout <span class="op">=</span> BIDSLayout(fmriprep_dir,</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>                   config<span class="op">=</span>[<span class="st">'bids'</span>,<span class="st">'derivatives'</span>])</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">#Get resting state data (preprocessed, mask, and confounds file)</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>func_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>                        datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>                        desc<span class="op">=</span><span class="st">'preproc'</span>,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>                        space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>                        extension<span class="op">=</span><span class="st">'nii.gz'</span>,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>                        return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>mask_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>                        datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>                        desc<span class="op">=</span><span class="st">'brain'</span>,</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>                        suffix<span class="op">=</span><span class="st">"mask"</span>,</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>                        space<span class="op">=</span><span class="st">'MNI152NLin2009cAsym'</span>,</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>                        extension<span class="op">=</span><span class="st">'nii.gz'</span>,</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>                        return_type<span class="op">=</span><span class="st">'file'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>confound_files <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>                            datatype<span class="op">=</span><span class="st">'func'</span>,</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>                            task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>                            desc<span class="op">=</span><span class="st">'confounds'</span>,</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>                            extension<span class="op">=</span><span class="st">'tsv'</span>,</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>                            return_type<span class="op">=</span><span class="st">'file'</span>)</span></code></pre>
</div>
<p>Now that we have a list of subjects to peform our analysis on, let’s
load up our parcellation template file</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co">#Load separated parcellation</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>parcel_file <span class="op">=</span> <span class="st">'../resources/rois/yeo_2011/Yeo_JNeurophysiol11_MNI152/relabeled_yeo_atlas.nii.gz'</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>yeo_7 <span class="op">=</span> nimg.load_img(parcel_file)</span></code></pre>
</div>
<p>Now we’ll import a package from <code>nilearn</code>, called
<code>input_data</code> which allows us to pull data using the
parcellation file, and at the same time applying data cleaning!</p>
<p>We first create an object using the parcellation file
<code>yeo_7</code> and our cleaning settings which are the
following:</p>
<p>Settings to use:</p>
<ul>
<li>Confounds: trans_x, trans_y, trans_z, rot_x, rot_y, rot_z,
white_matter, csf, global_signal</li>
<li>Temporal Derivatives: Yes</li>
<li>high_pass = 0.009</li>
<li>low_pass = 0.08</li>
<li>detrend = True</li>
<li>standardize = True</li>
</ul>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> nilearn <span class="im">import</span> input_data</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>masker <span class="op">=</span> input_data.NiftiLabelsMasker(labels_img<span class="op">=</span>yeo_7,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>                                      standardize<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>                                      memory<span class="op">=</span><span class="st">'nilearn_cache'</span>,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>                                      verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>                                      detrend<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>                                     low_pass <span class="op">=</span> <span class="fl">0.08</span>,</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>                                     high_pass <span class="op">=</span> <span class="fl">0.009</span>,</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                                     t_r<span class="op">=</span><span class="dv">2</span>)</span></code></pre>
</div>
<p>The object <code>masker</code> is now able to be used on <em>any
functional image of the same size</em>. The
<code>input_data.NiftiLabelsMasker</code> object is a wrapper that
applies parcellation, cleaning and averaging to an functional image. For
example let’s apply this to our first subject:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Pull the first subject's data</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>func_file <span class="op">=</span> func_files[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>mask_file <span class="op">=</span> mask_files[<span class="dv">0</span>]</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>confound_file <span class="op">=</span> confound_files[<span class="dv">0</span>]</span></code></pre>
</div>
<p>Before we go ahead and start using the <code>masker</code> that we’ve
created, we have to do some preparatory steps. The following should be
done prior to use the <code>masker</code> object:</p>
<ol style="list-style-type: decimal">
<li>Make your confounds matrix (as we’ve done in Episode 06)</li>
<li>Drop Dummy TRs that are to be excluded from our cleaning,
parcellation, and averaging step</li>
</ol>
<p>To help us with the first part, let’s define a function to help
extract our confound regressors from the .tsv file for us. Note that
we’ve handled pulling the appropriate
<code>{confounds}_derivative1</code> columns for you! You just need to
supply the base regressors!</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co">#Refer to part_06 for code + explanation</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="kw">def</span> extract_confounds(confound_tsv,confounds,dt<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">    Arguments:</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">        confound_tsv                    Full path to confounds.tsv</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">        confounds                       A list of confounder variables to extract</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">        dt                              Compute temporal derivatives [default = True]</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">    Outputs:</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co">        confound_mat                    </span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    </span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="cf">if</span> dt:    </span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>        dt_names <span class="op">=</span> [<span class="st">'</span><span class="sc">{}</span><span class="st">_derivative1'</span>.<span class="bu">format</span>(c) <span class="cf">for</span> c <span class="kw">in</span> confounds]</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>        confounds <span class="op">=</span> confounds <span class="op">+</span> dt_names</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    </span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    <span class="co">#Load in data using Pandas then extract relevant columns</span></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    confound_df <span class="op">=</span> pd.read_csv(confound_tsv,delimiter<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>) </span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    confound_df <span class="op">=</span> confound_df[confounds]</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>    </span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a> </span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>    <span class="co">#Convert into a matrix of values (timepoints)x(variable)</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>    confound_mat <span class="op">=</span> confound_df.values </span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>    </span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>    <span class="co">#Return confound matrix</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>    <span class="cf">return</span> confound_mat</span></code></pre>
</div>
<p>Finally we’ll set up our image file for confound regression (as we
did in Episode 6). To do this we’ll drop 4 TRs from <em>both our
functional image and our confounds file</em>. Note that our
<code>masker</code> object will not do this for us!</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co">#Load functional image</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>tr_drop <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>func_img <span class="op">=</span> nimg.load_img(func_file)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#Remove the first 4 TRs</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>func_img <span class="op">=</span> func_img.slicer[:,:,:,tr_drop:]</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#Use the above function to pull out a confound matrix</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>confounds <span class="op">=</span> extract_confounds(confound_file,</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>                              [<span class="st">'trans_x'</span>,<span class="st">'trans_y'</span>,<span class="st">'trans_z'</span>,</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>                               <span class="st">'rot_x'</span>,<span class="st">'rot_y'</span>,<span class="st">'rot_z'</span>,</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>                               <span class="st">'global_signal'</span>,</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>                               <span class="st">'white_matter'</span>,<span class="st">'csf'</span>])</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co">#Drop the first 4 rows of the confounds matrix</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>confounds <span class="op">=</span> confounds[tr_drop:,:] </span></code></pre>
</div>
<div class="section level3">
<h3 id="using-the-masker">Using the masker<a class="anchor" aria-label="anchor" href="#using-the-masker"></a>
</h3>
<p>Finally with everything set up, we can now use the masker to perform
our:</p>
<ol style="list-style-type: decimal">
<li>Confounds cleaning</li>
<li>Parcellation</li>
<li>Averaging within a parcel All in one step!</li>
</ol>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co">#Apply cleaning, parcellation and extraction to functional data</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>cleaned_and_averaged_time_series <span class="op">=</span> masker.fit_transform(func_img,confounds)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>cleaned_and_averaged_time_series.shape</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(147,43)</code></pre>
</div>
<p>Just to be clear, this data is <em>automatically parcellated for you,
and, in addition, is cleaned using the confounds you’ve specified
already!</em></p>
<p>The result of running <code>masker.fit_transform</code> is a matrix
that has:</p>
<ul>
<li>Rows matching the number of timepoints (148)</li>
<li>Columns, each for one of the ROIs that are extracted (43)</li>
</ul>
<p><strong>But wait!</strong></p>
<p>We originally had <strong>50 ROIs</strong>, what happened to 3 of
them? It turns out that <code>masker</code> drops ROIs that are empty
(i.e contain no brain voxels inside of them), this means that 3 of our
atlas’ parcels did not correspond to any region with signal! To see
which ROIs are kept after computing a parcellation you can look at the
<code>labels_</code> property of <code>masker</code>:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="bu">print</span>(masker.labels_)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of labels"</span>, <span class="bu">len</span>(masker.labels_))</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>[1, 2, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 49]
Number of labels 43</code></pre>
</div>
<p>This means that our ROIs of interest (44 and 46) <em>cannot be
accessed using the 44th and 46th columns directly</em>!</p>
<p>There are many strategies to deal with this weirdness. What we’re
going to do is to create a new array that fills in the regions that were
removed with <code>0</code> values. It might seem a bit weird now, but
it’ll simplify things when we start working with multiple subjects!</p>
<p>First we’ll identify all ROIs from the original atlas. We’re going to
use the <code>numpy</code> package which will provide us with functions
to work with our image arrays:</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co"># Get the label numbers from the atlas</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>atlas_labels <span class="op">=</span> np.unique(yeo_7.get_fdata().astype(<span class="bu">int</span>))</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co"># Get number of labels that we have</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>NUM_LABELS <span class="op">=</span> <span class="bu">len</span>(atlas_labels)</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="bu">print</span>(NUM_LABELS)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code><span><span class="fl">50</span></span></code></pre>
</div>
<p>Now we’re going to create an array that contains:</p>
<ul>
<li>A number of rows matching the number of timepoints</li>
<li>A number of columns matching the total number of regions</li>
</ul>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># Remember fMRI images are of size (x,y,z,t)</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="co"># where t is the number of timepoints</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>num_timepoints <span class="op">=</span> func_img.shape[<span class="dv">3</span>]</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co"># Create an array of zeros that has the correct size</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>final_signal <span class="op">=</span> np.zeros((num_timepoints, NUM_LABELS))</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co"># Get regions that are kept</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>regions_kept <span class="op">=</span> np.array(masker.labels_)</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co"># Fill columns matching labels with signal values</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>final_signal[:, regions_kept] <span class="op">=</span> cleaned_and_averaged_time_series</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="bu">print</span>(final_signal.shape)</span></code></pre>
</div>
<p>It’s a bit of work, but now we have an array where:</p>
<ol style="list-style-type: decimal">
<li>The column number matches the ROI label number</li>
<li>Any column that is lost during the <code>masker.fit_transform</code>
is filled with <code>0</code> values!</li>
</ol>
<p>To get the columns corresponding to the regions that we’ve kept, we
can simply use the <code>regions_kept</code> variable to select columns
corresponding to the regions that weren’t removed:</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>valid_regions_signal <span class="op">=</span> final_signal[:, regions_kept]</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="bu">print</span>(valid_regions_signal.shape)</span></code></pre>
</div>
<p>This is identical to the original output of
<code>masker.fit_transform</code></p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>np.array_equal(</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>    valid_regions_signal,</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>    cleaned_and_averaged_time_series</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>)</span></code></pre>
</div>
<p>This might seem unnecessary for now, but as you’ll see in a bit,
it’ll come in handy when we deal with multiple subjects!d</p>
</div>
<div class="section level3">
<h3 id="calculating-connectivity">Calculating Connectivity<a class="anchor" aria-label="anchor" href="#calculating-connectivity"></a>
</h3>
<p>In fMRI imaging, connectivity typically refers to the <em>correlation
of the timeseries of 2 ROIs</em>. Therefore we can calculate a <em>full
connectivity matrix</em> by computing the correlation between <em>all
pairs of ROIs</em> in our parcellation scheme!</p>
<p>We’ll use another nilearn tool called
<code>ConnectivityMeasure</code> from <code>nilearn.connectome</code>.
This tool will perform the full set of pairwise correlations for us</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="im">from</span> nilearn.connectome <span class="im">import</span> ConnectivityMeasure</span></code></pre>
</div>
<p>Like the masker, we need to make an object that will calculate
connectivity for us.</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>correlation_measure <span class="op">=</span> ConnectivityMeasure(kind<span class="op">=</span><span class="st">'correlation'</span>)</span></code></pre>
</div>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout1"></a>
</h3>
<div class="callout-content">
<p>Try using <code>SHIFT-TAB</code> to see what options you can put into
the <code>kind</code> argument of <code>ConnectivityMeasure</code></p>
</div>
</div>
</div>
<p>Then we use <code>correlation_measure.fit_transform()</code> in order
to calculate the full correlation matrix for our parcellated data!</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>full_correlation_matrix <span class="op">=</span> correlation_measure.fit_transform([cleaned_and_averaged_time_series])</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>full_correlation_matrix.shape</span></code></pre>
</div>
<div id="callout2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout2"></a>
</h3>
<div class="callout-content">
<p>Note that we’re using a list <code>[final_signal]</code>, this is
because <code>correlation_measure</code> works on a <em>list of
subjects</em>. We’ll take advantage of this later!</p>
</div>
</div>
</div>
<p>The result is a matrix which has:</p>
<ul>
<li>A number of rows matching the number of ROIs in our parcellation
atlas</li>
<li>A number of columns, that also matches the number of ROIs in our
parcellation atlas</li>
</ul>
<p>You can read this correlation matrix as follows:</p>
<p>Suppose we wanted to know the correlation between ROI 30 and ROI
40</p>
<ul>
<li>Then Row 30, Column 40 gives us this correlation.</li>
<li>Row 40, Column 40 can also give us this correlation</li>
</ul>
<p>This is because the correlation of <span class="math inline">\(A
--&gt; B = B --&gt; A\)</span></p>
<div id="callout3" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Callout<a class="anchor" aria-label="anchor" href="#callout3"></a>
</h3>
<div class="callout-content">
<p><strong>NOTE</strong>: Remember we were supposed to lose 7 regions
from the <code>masker.fit_transform</code> step. The correlations for
these regions will be 0!</p>
</div>
</div>
</div>
<p>Let’s try pulling the correlation for ROI 44 and 46!</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>full_correlation_matrix[<span class="dv">0</span>, <span class="dv">43</span>, <span class="dv">45</span>]</span></code></pre>
</div>
<p>Note that it’ll be the same if we swap the rows and columns!</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>full_correlation_matrix[<span class="dv">0</span>, <span class="dv">45</span>, <span class="dv">43</span>]</span></code></pre>
</div>
<div id="exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise" class="callout-inner">
<h3 class="callout-title">Exercise<a class="anchor" aria-label="anchor" href="#exercise"></a>
</h3>
<div class="callout-content">
<p>Apply the data extract process shown above to all subjects in our
subject list and collect the results. Your job is to fill in the
blanks!</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># First we're going to create some empty lists to store all our data in!</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>ctrl_subjects <span class="op">=</span> []</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>schz_subjects <span class="op">=</span> []</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co"># We're going to keep track of each of our subjects labels here</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="co"># pulled from masker.labels_</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>labels_list <span class="op">=</span> []</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a><span class="co"># Get the number of unique labels in our parcellation</span></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a><span class="co"># We'll use this to figure out how many columns to make (as we did earlier)</span></span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a>atlas_labels <span class="op">=</span> np.unique(yeo_7.get_fdata().astype(<span class="bu">int</span>))</span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>NUM_LABELS <span class="op">=</span> <span class="bu">len</span>(atlas_labels)</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a><span class="co"># Set the list of confound variables we'll be using</span></span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a>confound_variables <span class="op">=</span> [<span class="st">'trans_x'</span>,<span class="st">'trans_y'</span>,<span class="st">'trans_z'</span>,</span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>                               <span class="st">'rot_x'</span>,<span class="st">'rot_y'</span>,<span class="st">'rot_z'</span>,</span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a>                               <span class="st">'global_signal'</span>,</span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a>                               <span class="st">'white_matter'</span>,<span class="st">'csf'</span>]</span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a><span class="co"># Number of TRs we should drop</span></span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a>TR_DROP<span class="op">=</span><span class="dv">4</span></span>
<span id="cb23-23"><a href="#cb23-23" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" tabindex="-1"></a><span class="co"># Lets get all the subjects we have</span></span>
<span id="cb23-25"><a href="#cb23-25" tabindex="-1"></a>subjects <span class="op">=</span> layout.get_subjects()</span>
<span id="cb23-26"><a href="#cb23-26" tabindex="-1"></a><span class="cf">for</span> sub <span class="kw">in</span> subjects:</span>
<span id="cb23-27"><a href="#cb23-27" tabindex="-1"></a>    </span>
<span id="cb23-28"><a href="#cb23-28" tabindex="-1"></a>    <span class="co">#Get the functional file for the subject (MNI space)</span></span>
<span id="cb23-29"><a href="#cb23-29" tabindex="-1"></a>    func_file <span class="op">=</span> layout.get(subject<span class="op">=</span>??,</span>
<span id="cb23-30"><a href="#cb23-30" tabindex="-1"></a>                           datatype<span class="op">=</span><span class="st">'??'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb23-31"><a href="#cb23-31" tabindex="-1"></a>                           desc<span class="op">=</span><span class="st">'??'</span>,</span>
<span id="cb23-32"><a href="#cb23-32" tabindex="-1"></a>                           space<span class="op">=</span><span class="st">'??'</span></span>
<span id="cb23-33"><a href="#cb23-33" tabindex="-1"></a>                           extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb23-34"><a href="#cb23-34" tabindex="-1"></a>                           return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb23-35"><a href="#cb23-35" tabindex="-1"></a>    </span>
<span id="cb23-36"><a href="#cb23-36" tabindex="-1"></a>    <span class="co">#Get the confounds file for the subject (MNI space)</span></span>
<span id="cb23-37"><a href="#cb23-37" tabindex="-1"></a>    confound_file<span class="op">=</span>layout.get(subject<span class="op">=</span>??, datatype<span class="op">=</span><span class="st">'??'</span>,</span>
<span id="cb23-38"><a href="#cb23-38" tabindex="-1"></a>                             task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb23-39"><a href="#cb23-39" tabindex="-1"></a>                             desc<span class="op">=</span><span class="st">'??'</span>,</span>
<span id="cb23-40"><a href="#cb23-40" tabindex="-1"></a>                             extension<span class="op">=</span><span class="st">'tsv'</span>,</span>
<span id="cb23-41"><a href="#cb23-41" tabindex="-1"></a>                             return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb23-42"><a href="#cb23-42" tabindex="-1"></a>    </span>
<span id="cb23-43"><a href="#cb23-43" tabindex="-1"></a>    <span class="co">#Load the functional file in</span></span>
<span id="cb23-44"><a href="#cb23-44" tabindex="-1"></a>    func_img <span class="op">=</span> nimg.load_img(??)</span>
<span id="cb23-45"><a href="#cb23-45" tabindex="-1"></a>    </span>
<span id="cb23-46"><a href="#cb23-46" tabindex="-1"></a>    <span class="co">#Drop the first 4 TRs</span></span>
<span id="cb23-47"><a href="#cb23-47" tabindex="-1"></a>    func_img <span class="op">=</span> func_img.slicer[??,??,??,??]</span>
<span id="cb23-48"><a href="#cb23-48" tabindex="-1"></a>    </span>
<span id="cb23-49"><a href="#cb23-49" tabindex="-1"></a>    </span>
<span id="cb23-50"><a href="#cb23-50" tabindex="-1"></a>    <span class="co">#Extract the confound variables using the function</span></span>
<span id="cb23-51"><a href="#cb23-51" tabindex="-1"></a>    confounds <span class="op">=</span> extract_confounds(confound_file,</span>
<span id="cb23-52"><a href="#cb23-52" tabindex="-1"></a>                                  confound_variables)</span>
<span id="cb23-53"><a href="#cb23-53" tabindex="-1"></a>    </span>
<span id="cb23-54"><a href="#cb23-54" tabindex="-1"></a>    <span class="co">#Drop the first 4 rows from the confound matrix</span></span>
<span id="cb23-55"><a href="#cb23-55" tabindex="-1"></a>    confounds <span class="op">=</span> confounds[??]</span>
<span id="cb23-56"><a href="#cb23-56" tabindex="-1"></a>    </span>
<span id="cb23-57"><a href="#cb23-57" tabindex="-1"></a>    <span class="co"># Make our array of zeros to fill out</span></span>
<span id="cb23-58"><a href="#cb23-58" tabindex="-1"></a>    <span class="co"># Number of rows should match number of timepoints</span></span>
<span id="cb23-59"><a href="#cb23-59" tabindex="-1"></a>    <span class="co"># Number of columns should match the total number of regions</span></span>
<span id="cb23-60"><a href="#cb23-60" tabindex="-1"></a>    fill_array <span class="op">=</span> np.zeros((func_img.shape[??], ??))</span>
<span id="cb23-61"><a href="#cb23-61" tabindex="-1"></a>    </span>
<span id="cb23-62"><a href="#cb23-62" tabindex="-1"></a>    <span class="co">#Apply the parcellation + cleaning to our data</span></span>
<span id="cb23-63"><a href="#cb23-63" tabindex="-1"></a>    <span class="co">#What function of masker is used to clean and average data?</span></span>
<span id="cb23-64"><a href="#cb23-64" tabindex="-1"></a>    time_series <span class="op">=</span> masker.fit_transform(??,??)</span>
<span id="cb23-65"><a href="#cb23-65" tabindex="-1"></a>    </span>
<span id="cb23-66"><a href="#cb23-66" tabindex="-1"></a>    <span class="co"># Get the regions that were kept for this scan</span></span>
<span id="cb23-67"><a href="#cb23-67" tabindex="-1"></a>    regions_kept <span class="op">=</span> np.array(masker.labels_)</span>
<span id="cb23-68"><a href="#cb23-68" tabindex="-1"></a>    </span>
<span id="cb23-69"><a href="#cb23-69" tabindex="-1"></a>    <span class="co"># Fill the array, this is what we'll use</span></span>
<span id="cb23-70"><a href="#cb23-70" tabindex="-1"></a>    <span class="co"># to make sure that all our array are of the same size</span></span>
<span id="cb23-71"><a href="#cb23-71" tabindex="-1"></a>    fill_array[:, ??] <span class="op">=</span> time_series</span>
<span id="cb23-72"><a href="#cb23-72" tabindex="-1"></a>    </span>
<span id="cb23-73"><a href="#cb23-73" tabindex="-1"></a>    <span class="co">#If the subject ID starts with a "1" then they are control</span></span>
<span id="cb23-74"><a href="#cb23-74" tabindex="-1"></a>    <span class="cf">if</span> sub.startswith(<span class="st">'1'</span>):</span>
<span id="cb23-75"><a href="#cb23-75" tabindex="-1"></a>        ctrl_subjects.append(fill_array)</span>
<span id="cb23-76"><a href="#cb23-76" tabindex="-1"></a>    <span class="co">#If the subject ID starts with a "5" then they are case (case of schizophrenia)</span></span>
<span id="cb23-77"><a href="#cb23-77" tabindex="-1"></a>    <span class="cf">if</span> sub.startswith(<span class="st">'5'</span>):</span>
<span id="cb23-78"><a href="#cb23-78" tabindex="-1"></a>        schz_subjects.append(fill_array)</span></code></pre>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co"># First we're going to create some empty lists to store all our data in!</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>pooled_subjects <span class="op">=</span> []</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>ctrl_subjects <span class="op">=</span> []</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>schz_subjects <span class="op">=</span> []</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="co">#Which confound variables should we use?</span></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>confound_variables <span class="op">=</span> [<span class="st">'trans_x'</span>,<span class="st">'trans_y'</span>,<span class="st">'trans_z'</span>,</span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>                               <span class="st">'rot_x'</span>,<span class="st">'rot_y'</span>,<span class="st">'rot_z'</span>,</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>                               <span class="st">'global_signal'</span>,</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a>                               <span class="st">'white_matter'</span>,<span class="st">'csf'</span>]</span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a><span class="cf">for</span> sub <span class="kw">in</span> subjects:</span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a>    </span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a>    <span class="co">#Get the functional file for the subject (MNI space)</span></span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a>    func_file <span class="op">=</span> layout.get(subject<span class="op">=</span>sub,</span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a>                           datatype<span class="op">=</span><span class="st">'func'</span>, task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb24-16"><a href="#cb24-16" tabindex="-1"></a>                           desc<span class="op">=</span><span class="st">'preproc'</span>,</span>
<span id="cb24-17"><a href="#cb24-17" tabindex="-1"></a>                           extension<span class="op">=</span><span class="st">"nii.gz"</span>,</span>
<span id="cb24-18"><a href="#cb24-18" tabindex="-1"></a>                           return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb24-19"><a href="#cb24-19" tabindex="-1"></a>    </span>
<span id="cb24-20"><a href="#cb24-20" tabindex="-1"></a>    <span class="co">#Get the confounds file for the subject (MNI space)</span></span>
<span id="cb24-21"><a href="#cb24-21" tabindex="-1"></a>    confound_file<span class="op">=</span>layout.get(subject<span class="op">=</span>sub, datatype<span class="op">=</span><span class="st">'func'</span>,</span>
<span id="cb24-22"><a href="#cb24-22" tabindex="-1"></a>                             task<span class="op">=</span><span class="st">'rest'</span>,</span>
<span id="cb24-23"><a href="#cb24-23" tabindex="-1"></a>                             desc<span class="op">=</span><span class="st">'confounds'</span>,</span>
<span id="cb24-24"><a href="#cb24-24" tabindex="-1"></a>                             extension<span class="op">=</span><span class="st">'tsv'</span>,</span>
<span id="cb24-25"><a href="#cb24-25" tabindex="-1"></a>                             return_type<span class="op">=</span><span class="st">'file'</span>)[<span class="dv">0</span>]</span>
<span id="cb24-26"><a href="#cb24-26" tabindex="-1"></a>    </span>
<span id="cb24-27"><a href="#cb24-27" tabindex="-1"></a>    <span class="co">#Load the functional file in</span></span>
<span id="cb24-28"><a href="#cb24-28" tabindex="-1"></a>    func_img <span class="op">=</span> nimg.load_img(func_file)</span>
<span id="cb24-29"><a href="#cb24-29" tabindex="-1"></a>    </span>
<span id="cb24-30"><a href="#cb24-30" tabindex="-1"></a>    <span class="co">#Drop the first 4 TRs</span></span>
<span id="cb24-31"><a href="#cb24-31" tabindex="-1"></a>    func_img <span class="op">=</span> func_img.slicer[:,:,:,tr_drop:]</span>
<span id="cb24-32"><a href="#cb24-32" tabindex="-1"></a>    </span>
<span id="cb24-33"><a href="#cb24-33" tabindex="-1"></a>    </span>
<span id="cb24-34"><a href="#cb24-34" tabindex="-1"></a>    <span class="co">#Extract the confound variables using the function</span></span>
<span id="cb24-35"><a href="#cb24-35" tabindex="-1"></a>    confounds <span class="op">=</span> extract_confounds(confound_file,</span>
<span id="cb24-36"><a href="#cb24-36" tabindex="-1"></a>                                  confound_variables)</span>
<span id="cb24-37"><a href="#cb24-37" tabindex="-1"></a>    </span>
<span id="cb24-38"><a href="#cb24-38" tabindex="-1"></a>    <span class="co">#Drop the first 4 rows from the confound matrix</span></span>
<span id="cb24-39"><a href="#cb24-39" tabindex="-1"></a>    <span class="co">#Which rows and columns should we keep?</span></span>
<span id="cb24-40"><a href="#cb24-40" tabindex="-1"></a>    confounds <span class="op">=</span> confounds[tr_drop:,:]</span>
<span id="cb24-41"><a href="#cb24-41" tabindex="-1"></a>    </span>
<span id="cb24-42"><a href="#cb24-42" tabindex="-1"></a>    <span class="co">#Apply the parcellation + cleaning to our data</span></span>
<span id="cb24-43"><a href="#cb24-43" tabindex="-1"></a>    <span class="co">#What function of masker is used to clean and average data?</span></span>
<span id="cb24-44"><a href="#cb24-44" tabindex="-1"></a>    time_series <span class="op">=</span> masker.fit_transform(func_img,confounds)</span>
<span id="cb24-45"><a href="#cb24-45" tabindex="-1"></a>    </span>
<span id="cb24-46"><a href="#cb24-46" tabindex="-1"></a>    <span class="co">#This collects a list of all subjects</span></span>
<span id="cb24-47"><a href="#cb24-47" tabindex="-1"></a>    pooled_subjects.append(time_series)</span>
<span id="cb24-48"><a href="#cb24-48" tabindex="-1"></a>    </span>
<span id="cb24-49"><a href="#cb24-49" tabindex="-1"></a>    <span class="co">#If the subject ID starts with a "1" then they are control</span></span>
<span id="cb24-50"><a href="#cb24-50" tabindex="-1"></a>    <span class="cf">if</span> sub.startswith(<span class="st">'1'</span>):</span>
<span id="cb24-51"><a href="#cb24-51" tabindex="-1"></a>        ctrl_subjects.append(time_series)</span>
<span id="cb24-52"><a href="#cb24-52" tabindex="-1"></a>    <span class="co">#If the subject ID starts with a "5" then they are case (case of schizophrenia)</span></span>
<span id="cb24-53"><a href="#cb24-53" tabindex="-1"></a>    <span class="cf">if</span> sub.startswith(<span class="st">'5'</span>):</span>
<span id="cb24-54"><a href="#cb24-54" tabindex="-1"></a>        schz_subjects.append(time_series)</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<p>The result of all of this code is that:</p>
<ol style="list-style-type: decimal">
<li>Subjects who start with a “1” in their ID, are controls, and are
placed into the <code>ctrl_subjects</code> list</li>
<li>Subjects who start with a “2” in their ID, have schizophrenia, and
are placed into the <code>schz_subjects</code> list</li>
</ol>
<p>What’s actually being placed into the list? The cleaned, parcellated
time series data for each subject (the output of
<code>masker.fit_transform</code>)!</p>
<p>A helpful trick is that we can re-use the
<code>correlation_measure</code> object we made earlier and apply it to
a <em>list of subject data</em>!</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>ctrl_correlation_matrices <span class="op">=</span> correlation_measure.fit_transform(ctrl_subjects)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>schz_correlation_matrices <span class="op">=</span> correlation_measure.fit_transform(schz_subjects)</span></code></pre>
</div>
<p>At this point, we have correlation matrices for each subject across
two populations. The final step is to examine the differences between
these groups in their correlation between ROI 43 and ROI 45.</p>
</div>
<div class="section level3">
<h3 id="visualizing-correlation-matrices-and-group-differences">Visualizing Correlation Matrices and Group Differences<a class="anchor" aria-label="anchor" href="#visualizing-correlation-matrices-and-group-differences"></a>
</h3>
<p>An important step in any analysis is visualizing the data that we
have. We’ve cleaned data, averaged data and calculated correlations but
we don’t actually know what it looks like! Visualizing data is important
to ensure that we don’t throw pure nonsense into our final statistical
analysis</p>
<p>To visualize data we’ll be using a python package called
<code>seaborn</code> which will allow us to create statistical
visualizations with not much effort.</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre>
</div>
<p>We can view a single subject’s correlation matrix by using
<code>seaborn</code>’s <code>heatmap</code> function:</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>sns.heatmap(ctrl_correlation_matrices[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">'RdBu_r'</span>)</span></code></pre>
</div>
<figure><img src="../fig/heatmap.png" class="img-responsive figure mx-auto d-block" alt="Connectivity Matrix Heatmap"></figure><p>Recall that cleaning and parcellating the data causes some ROIs to
get dropped. We dealt with this by filling an array of zeros
(<code>fill_array</code>) only for columns where the regions are kept
(<code>regions_kept</code>). This means that we’ll have some correlation
values that are 0!</p>
<p>This is more apparent if we plot the data slightly differently. For
demonstrative purposes we’ve:</p>
<ul>
<li>Taken the absolute value of our correlations so that the 0’s are the
darkest color</li>
<li>Used a different color scheme</li>
</ul>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>sns.heatmap(np.<span class="bu">abs</span>(ctrl_correlation_matrices[<span class="dv">0</span>]), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span></code></pre>
</div>
<figure><img src="../fig/heatmap_show_zeroes.png" class="img-responsive figure mx-auto d-block" alt="Absolute Matrix Heatmap Zeros Highlighted"></figure><p>The dark lines in the correlation matrix correspond to regions that
were dropped and therefore have 0 correlation!</p>
<p>We can now pull our ROI 44 and 46 by indexing our list of correlation
matrices as if it were a 3D array (kind of like an MR volume). Take a
look at the shape:</p>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="bu">print</span>(ctrl_correlation_matrices.shape)</span></code></pre>
</div>
<p>This is of form:</p>
<p><code>ctrl_correlation_matrices[subject_index, row_index,
column_index]</code></p>
<p>Now we’re going to pull out just the correlation values between ROI
43 and 45 <em>across all our subjects</em>. This can be done using
standard array indexing:</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>ctrl_roi_vec <span class="op">=</span> ctrl_correlation_matrices[:,<span class="dv">43</span>,<span class="dv">45</span>]</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>schz_roi_vec <span class="op">=</span> schz_correlation_matrices[:,<span class="dv">43</span>,<span class="dv">45</span>]</span></code></pre>
</div>
<p>Next we’re going to arrange this data into a table. We’ll create two
tables (called dataframes in the python package we’re using,
<code>pandas</code>)</p>
<div class="codewrapper sourceCode" id="cb31">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="co">#Create control dataframe</span></span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>ctrl_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>{<span class="st">'dmn_corr'</span>:ctrl_roi_vec, <span class="st">'group'</span>:<span class="st">'control'</span>})</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>ctrl_df.head()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="co"># Create the schizophrenia dataframe</span></span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>scz_df <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>{<span class="st">'dmn_corr'</span>:schz_roi_vec, <span class="st">'group'</span> : <span class="st">'schizophrenia'</span>})</span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>scz_df.head()</span></code></pre>
</div>
<p>The result is:</p>
<ul>
<li><p><code>ctrl_df</code> a table containing the correlation value for
each control subject, with an additional column with the group label,
which is ‘control’</p></li>
<li><p><code>scz_df</code> a table containing the correlation value for
each schizophrenia group subject, with an additional column with the
group label, which is ‘schizophrenia’</p></li>
</ul>
<p>For visualization we’re going to stack the two tables together…</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a><span class="co">#Stack the two dataframes together</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>df <span class="op">=</span> pd.concat([ctrl_df,scz_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a><span class="co"># Show some random samples from dataframe</span></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>df.sample(n<span class="op">=</span><span class="dv">3</span>)</span></code></pre>
</div>
<p>Finally we’re going to visualize the results using the python package
<code>seaborn</code>!</p>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="co">#Visualize results</span></span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a><span class="co"># Create a figure canvas of equal width and height</span></span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>plot <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>                  </span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a><span class="co"># Create a box plot, with the x-axis as group</span></span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a><span class="co">#the y-axis as the correlation value</span></span>
<span id="cb34-8"><a href="#cb34-8" tabindex="-1"></a>ax <span class="op">=</span> sns.boxplot(x<span class="op">=</span><span class="st">'group'</span>,y<span class="op">=</span><span class="st">'dmn_corr'</span>,data<span class="op">=</span>df,palette<span class="op">=</span><span class="st">'Set3'</span>)</span>
<span id="cb34-9"><a href="#cb34-9" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" tabindex="-1"></a><span class="co"># Create a "swarmplot" as well, you'll see what this is..</span></span>
<span id="cb34-11"><a href="#cb34-11" tabindex="-1"></a>ax <span class="op">=</span> sns.swarmplot(x<span class="op">=</span><span class="st">'group'</span>,y<span class="op">=</span><span class="st">'dmn_corr'</span>,data<span class="op">=</span>df,color<span class="op">=</span><span class="st">'0.25'</span>)</span>
<span id="cb34-12"><a href="#cb34-12" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" tabindex="-1"></a><span class="co"># Set the title and labels of the figure</span></span>
<span id="cb34-14"><a href="#cb34-14" tabindex="-1"></a>ax.set_title(<span class="st">'DMN Intra-network Connectivity'</span>)</span>
<span id="cb34-15"><a href="#cb34-15" tabindex="-1"></a>ax.set_ylabel(<span class="vs">r'Intra-network connectivity $\mu_\rho$'</span>)</span>
<span id="cb34-16"><a href="#cb34-16" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<p>Although the results here aren’t significant they seem to indicate
that there might be three subclasses in our schizophrenia group - of
course we’d need <em>a lot</em> more data to confirm this! The
interpretation of these results should ideally be based on some <em>a
priori</em> hypothesis!</p>
</div>
</section><section id="congratulations"><h2 class="section-heading">Congratulations!<a class="anchor" aria-label="anchor" href="#congratulations"></a>
</h2>
<hr class="half-width">
<p>Hopefully now you understand that:</p>
<ol style="list-style-type: decimal">
<li>fMRI data needs to be pre-processed before analyzing</li>
<li>Manipulating images in python is easily done using
<code>nilearn</code> and <code>nibabel</code>
</li>
<li>You can also do post-processing like confound/nuisance regression
using <code>nilearn</code>
</li>
<li>Parcellating is a method of simplifying and “averaging” data. The
type of parcellation reflect assumptions you make about the structure of
your data</li>
<li>Functional Connectivity is really just time-series correlations
between two signals!</li>
</ol>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points<a class="anchor" aria-label="anchor" href="#keypoints1"></a>
</h3>
<div class="callout-content">
<ul>
<li>MR images are essentially 3D arrays where each voxel is represented
by an (i,j,k) index</li>
<li>Nilearn is Nibabel under the hood, knowing how Nibabel works is key
to understanding Nilearn</li>
</ul>
</div>
</div>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/SDC-BIDS-fMRI/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.3" class="external-link">sandpaper (0.16.3)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.4" class="external-link">pegboard (0.7.4)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/SDC-BIDS-fMRI/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/SDC-BIDS-fMRI/instructor/aio.html",
  "identifier": "https://carpentries-incubator.github.io/SDC-BIDS-fMRI/instructor/aio.html",
  "dateCreated": "2024-02-18",
  "dateModified": "2024-03-19",
  "datePublished": "2024-03-19"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

