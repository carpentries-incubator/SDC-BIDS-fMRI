{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to functional data cleaning using nilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement is the enemy of neuroimagers\n",
    "\n",
    "In task-based fMRI, if participants move during task-relevant moments\n",
    "- Get a huge **false task-related signal** that’s actually due to motion!\n",
    "\n",
    "In resting-state fMRI, movement can induce **false correlations** between brain regions\n",
    "\n",
    "\n",
    "Solving for this involves *modelling* our fMRI signal to be comprised of **true brain signal** and **confounder signals**. \n",
    "\n",
    "\n",
    "Our goal is to remove a majority (hopefully) of the **confounder signals** and acquire something *closer* to the **true signal**. \n",
    "\n",
    "This is achieved via **confound regression**, which is essentially fitting a linear model using confounds as regressors then subtracting it out from the signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up\n",
    "\n",
    "Let's load in some modules as we've done before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:00.978111Z",
     "iopub.status.busy": "2021-10-21T17:58:00.977501Z",
     "iopub.status.idle": "2021-10-21T17:58:02.445140Z",
     "shell.execute_reply": "2021-10-21T17:58:02.444220Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nilearn import image as image\n",
    "from nilearn import plotting as plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import bids\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our Motion Estimates\n",
    "\n",
    "The beauty of fMRIPREP is that it estimates a number of motion-related signals for you and outputs it into:\n",
    "\n",
    "**sub-xxxx_task-xxxx_desc-confounds_timeseries.tsv**\n",
    "\n",
    "This is basically a spreadsheet that has columns related to each motion estimate type and rows for timepoints. We can view these using a language-python package called `pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick out an fMRI file to clean and pull out the `confounds` file that fMRIPREP computed for us:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:02.454363Z",
     "iopub.status.busy": "2021-10-21T17:58:02.453522Z",
     "iopub.status.idle": "2021-10-21T17:58:04.479089Z",
     "shell.execute_reply": "2021-10-21T17:58:04.480543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerry/.pyenv/versions/3.8.0/envs/fmri-workshop/lib/python3.8/site-packages/bids/layout/models.py:98: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n",
      "  warnings.warn(\"The 'extension' entity currently excludes the leading dot ('.'). \"\n"
     ]
    }
   ],
   "source": [
    "sub = '10788'\n",
    "fmriprep_dir = '../data/ds000030/derivatives/fmriprep/'\n",
    "layout = bids.BIDSLayout(fmriprep_dir,validate=False,\n",
    "                        config=['bids','derivatives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:04.486253Z",
     "iopub.status.busy": "2021-10-21T17:58:04.485149Z",
     "iopub.status.idle": "2021-10-21T17:58:13.216388Z",
     "shell.execute_reply": "2021-10-21T17:58:13.217140Z"
    }
   },
   "outputs": [],
   "source": [
    "func_files = layout.get(subject=sub,\n",
    "                        datatype='func', task='rest',\n",
    "                        desc='preproc',\n",
    "                        space='MNI152NLin2009cAsym',\n",
    "                        extension='nii.gz',\n",
    "                       return_type='file')\n",
    "\n",
    "mask_files = layout.get(subject=sub,\n",
    "                        datatype='func', task='rest',\n",
    "                        desc='brain',\n",
    "                        suffix='mask',\n",
    "                        space='MNI152NLin2009cAsym',\n",
    "                        extension=\"nii.gz\",\n",
    "                       return_type='file')\n",
    "\n",
    "confound_files = layout.get(subject=sub,\n",
    "                            datatype='func', task='rest',\n",
    "                            desc='confounds',\n",
    "                           extension=\"tsv\",\n",
    "                           return_type='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.223750Z",
     "iopub.status.busy": "2021-10-21T17:58:13.222418Z",
     "iopub.status.idle": "2021-10-21T17:58:13.225703Z",
     "shell.execute_reply": "2021-10-21T17:58:13.225088Z"
    }
   },
   "outputs": [],
   "source": [
    "func_file = func_files[0]\n",
    "mask_file = mask_files[0]\n",
    "confound_file = confound_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `pandas` we can read in the `confounds` file as a spreadsheet and display some rows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.239930Z",
     "iopub.status.busy": "2021-10-21T17:58:13.238988Z",
     "iopub.status.idle": "2021-10-21T17:58:13.265172Z",
     "shell.execute_reply": "2021-10-21T17:58:13.266018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_signal</th>\n",
       "      <th>global_signal_derivative1</th>\n",
       "      <th>global_signal_derivative1_power2</th>\n",
       "      <th>global_signal_power2</th>\n",
       "      <th>csf</th>\n",
       "      <th>csf_derivative1</th>\n",
       "      <th>csf_derivative1_power2</th>\n",
       "      <th>csf_power2</th>\n",
       "      <th>white_matter</th>\n",
       "      <th>white_matter_derivative1</th>\n",
       "      <th>...</th>\n",
       "      <th>rot_y_power2</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>rot_z_derivative1</th>\n",
       "      <th>rot_z_power2</th>\n",
       "      <th>rot_z_derivative1_power2</th>\n",
       "      <th>motion_outlier00</th>\n",
       "      <th>motion_outlier01</th>\n",
       "      <th>motion_outlier02</th>\n",
       "      <th>motion_outlier03</th>\n",
       "      <th>motion_outlier04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>637.338734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406200.661813</td>\n",
       "      <td>739.137476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>546324.207951</td>\n",
       "      <td>690.585770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.106440e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636.074915</td>\n",
       "      <td>-1.263819</td>\n",
       "      <td>1.597238</td>\n",
       "      <td>404591.297637</td>\n",
       "      <td>733.465395</td>\n",
       "      <td>-5.672080</td>\n",
       "      <td>32.172496</td>\n",
       "      <td>537971.486092</td>\n",
       "      <td>690.591405</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>2.322536e-07</td>\n",
       "      <td>2.228900e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635.334148</td>\n",
       "      <td>-0.740767</td>\n",
       "      <td>0.548736</td>\n",
       "      <td>403649.479415</td>\n",
       "      <td>736.704948</td>\n",
       "      <td>3.239552</td>\n",
       "      <td>10.494700</td>\n",
       "      <td>542734.180052</td>\n",
       "      <td>690.250655</td>\n",
       "      <td>-0.340750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>8.016767e-07</td>\n",
       "      <td>1.709302e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>635.666896</td>\n",
       "      <td>0.332748</td>\n",
       "      <td>0.110722</td>\n",
       "      <td>404072.403097</td>\n",
       "      <td>729.656746</td>\n",
       "      <td>-7.048202</td>\n",
       "      <td>49.677150</td>\n",
       "      <td>532398.966746</td>\n",
       "      <td>689.965758</td>\n",
       "      <td>-0.284897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.016767e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636.584482</td>\n",
       "      <td>0.917586</td>\n",
       "      <td>0.841964</td>\n",
       "      <td>405239.802820</td>\n",
       "      <td>736.274307</td>\n",
       "      <td>6.617561</td>\n",
       "      <td>43.792115</td>\n",
       "      <td>542099.855032</td>\n",
       "      <td>689.997763</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>2.604632e-07</td>\n",
       "      <td>1.482312e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_signal  global_signal_derivative1  global_signal_derivative1_power2  \\\n",
       "0     637.338734                        NaN                               NaN   \n",
       "1     636.074915                  -1.263819                          1.597238   \n",
       "2     635.334148                  -0.740767                          0.548736   \n",
       "3     635.666896                   0.332748                          0.110722   \n",
       "4     636.584482                   0.917586                          0.841964   \n",
       "\n",
       "   global_signal_power2         csf  csf_derivative1  csf_derivative1_power2  \\\n",
       "0         406200.661813  739.137476              NaN                     NaN   \n",
       "1         404591.297637  733.465395        -5.672080               32.172496   \n",
       "2         403649.479415  736.704948         3.239552               10.494700   \n",
       "3         404072.403097  729.656746        -7.048202               49.677150   \n",
       "4         405239.802820  736.274307         6.617561               43.792115   \n",
       "\n",
       "      csf_power2  white_matter  white_matter_derivative1  ...  rot_y_power2  \\\n",
       "0  546324.207951    690.585770                       NaN  ...      0.000001   \n",
       "1  537971.486092    690.591405                  0.005635  ...      0.000002   \n",
       "2  542734.180052    690.250655                 -0.340750  ...      0.000001   \n",
       "3  532398.966746    689.965758                 -0.284897  ...      0.000002   \n",
       "4  542099.855032    689.997763                  0.032005  ...      0.000002   \n",
       "\n",
       "      rot_z  rot_z_derivative1  rot_z_power2  rot_z_derivative1_power2  \\\n",
       "0  0.000333                NaN  1.106440e-07                       NaN   \n",
       "1  0.000482           0.000149  2.322536e-07              2.228900e-08   \n",
       "2  0.000895           0.000413  8.016767e-07              1.709302e-07   \n",
       "3  0.000895           0.000000  8.016767e-07              0.000000e+00   \n",
       "4  0.000510          -0.000385  2.604632e-07              1.482312e-07   \n",
       "\n",
       "   motion_outlier00  motion_outlier01  motion_outlier02  motion_outlier03  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   motion_outlier04  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using \\t since it is tab-separated\n",
    "confound_df = pd.read_csv(confound_file,delimiter='\\t')\n",
    "confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column in this `DataFrame` called <code>confound_df</code> represents a specific confound variable. These are primarily derived from either:\n",
    "\n",
    "1. Physical head motion estimates (i.e `trans_x`, `trans_y`, `trans_z`, `rot_x`)\n",
    "2. Algorithms that estimate noise from the brain signal directly (i.e `global_signal`, `csf`)\n",
    "\n",
    "\n",
    "Each row represents values from a TR/sample. So the number of rows in your <code>confound_df</code> should match the number of TRs you have in the functional MR data. The choice of which confounds to use in functional imaging analysis is a source of large debate. We recommend that you check out these sources for a start:\n",
    "\n",
    "1. https://www.sciencedirect.com/science/article/pii/S1053811917302288#f0005\n",
    "2. https://www.sciencedirect.com/science/article/pii/S1053811917302288\n",
    "\n",
    "For now we're going to replicate the pre-processing (mostly) from the seminal Yeo1000 17-networks paper:\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/21653723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Yeo 2011 Pre-processing schema\n",
    "\n",
    "#### Confound regressors\n",
    "1. 6 motion parameters (`trans_x`, `trans_y`, `trans_z`, `rot_x`, `rot_y`, `rot_z`) \n",
    "2. Global signal (`global_signal`)\n",
    "3. Cerebral spinal fluid signal (`csf`)\n",
    "4. White matter signal (`white_matter`)   \n",
    "\n",
    "This is a total of 9 base confound regressor variables. Finally we add temporal derivatives of each of these signals as well (1 temporal derivative for each), the result is 18 confound regressors.\n",
    "\n",
    "***\n",
    "**Temporal Derivatives** are the changes in values across 2 consecutive samples. It represents change in signal over time. For example, when dealing with the confound variable \"trans_x\", which represents motion along the \"X\" direction, the temporal derivative represents *velocity in the X direction*. \n",
    "\n",
    "***\n",
    "\n",
    "#### Low/High pass filtering\n",
    "1. Low pass filtering cut-off: 0.08 \n",
    "2. High pass filtering cut-off: 0.009\n",
    "\n",
    "Low-pass filters out high frequency signals from our data. fMRI signals are slow evolving processes; any high frequency signals are likely due to noise. High-pass filters out any very low frequency signals (below 0.009Hz), which may be due to intrinsic scanner instabilities\n",
    "\n",
    "#### Drop dummy TRs\n",
    "During the initial stages of a functional scan there is a strong signal decay artifact. Thus, the first 4ish or so \n",
    "TRs are very high intensity signals that don't reflect the rest of the scan. Therefore we drop these timepoints. \n",
    "\n",
    "#### Censoring + Interpolation (leaving out)\n",
    "Censoring involves removal and interpolation of high-movement frames from the fMRI data. Interpolation is typically done using sophisticated algorithms much like [Power et al. 2014](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3849338/). \n",
    "\n",
    "**We won't be using censoring + interpolation since it's fairly complicated and would take up too much time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Confound variables for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting columns for confound regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll pick our base confound regressors as done in Yeo 2011's pre-processing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.311830Z",
     "iopub.status.busy": "2021-10-21T17:58:13.311122Z",
     "iopub.status.idle": "2021-10-21T17:58:13.313585Z",
     "shell.execute_reply": "2021-10-21T17:58:13.314136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select confounds\n",
    "confound_vars = ['trans_x','trans_y','trans_z',\n",
    "                 'rot_x','rot_y','rot_z',\n",
    "                 'global_signal',\n",
    "                 'csf', 'white_matter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to get derivatives for each of these columns. Luckily fMRIPrep provides this for us. Derivative columns are denoted as the following:\n",
    "\n",
    "- `{NAME_OF_COLUMN}_derivative1`\n",
    "\n",
    "Since typing is alot of work, we'll use a for-loop instead to pick the derivatives for our `confound_vars`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.319835Z",
     "iopub.status.busy": "2021-10-21T17:58:13.318959Z",
     "iopub.status.idle": "2021-10-21T17:58:13.322322Z",
     "shell.execute_reply": "2021-10-21T17:58:13.322853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans_x_derivative1', 'trans_y_derivative1', 'trans_z_derivative1', 'rot_x_derivative1', 'rot_y_derivative1', 'rot_z_derivative1', 'global_signal_derivative1', 'csf_derivative1', 'white_matter_derivative1']\n"
     ]
    }
   ],
   "source": [
    "# Get derivative column names\n",
    "derivative_columns = ['{}_derivative1'.format(c) for c\n",
    "                     in confound_vars]\n",
    "\n",
    "print(derivative_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll join these two lists together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.329419Z",
     "iopub.status.busy": "2021-10-21T17:58:13.327977Z",
     "iopub.status.idle": "2021-10-21T17:58:13.334621Z",
     "shell.execute_reply": "2021-10-21T17:58:13.333995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'global_signal', 'csf', 'white_matter', 'trans_x_derivative1', 'trans_y_derivative1', 'trans_z_derivative1', 'rot_x_derivative1', 'rot_y_derivative1', 'rot_z_derivative1', 'global_signal_derivative1', 'csf_derivative1', 'white_matter_derivative1']\n"
     ]
    }
   ],
   "source": [
    "final_confounds = confound_vars + derivative_columns\n",
    "print(final_confounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll use this list to pick columns from our confounds table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.364590Z",
     "iopub.status.busy": "2021-10-21T17:58:13.346007Z",
     "iopub.status.idle": "2021-10-21T17:58:13.369140Z",
     "shell.execute_reply": "2021-10-21T17:58:13.369749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_x</th>\n",
       "      <th>trans_y</th>\n",
       "      <th>trans_z</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>global_signal</th>\n",
       "      <th>csf</th>\n",
       "      <th>white_matter</th>\n",
       "      <th>trans_x_derivative1</th>\n",
       "      <th>trans_y_derivative1</th>\n",
       "      <th>trans_z_derivative1</th>\n",
       "      <th>rot_x_derivative1</th>\n",
       "      <th>rot_y_derivative1</th>\n",
       "      <th>rot_z_derivative1</th>\n",
       "      <th>global_signal_derivative1</th>\n",
       "      <th>csf_derivative1</th>\n",
       "      <th>white_matter_derivative1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028576</td>\n",
       "      <td>-0.070269</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>637.338734</td>\n",
       "      <td>739.137476</td>\n",
       "      <td>690.585770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022116</td>\n",
       "      <td>-0.052498</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>-0.002084</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>636.074915</td>\n",
       "      <td>733.465395</td>\n",
       "      <td>690.591405</td>\n",
       "      <td>-0.006459</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-1.263819</td>\n",
       "      <td>-5.672080</td>\n",
       "      <td>0.005635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024887</td>\n",
       "      <td>-0.048753</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>635.334148</td>\n",
       "      <td>736.704948</td>\n",
       "      <td>690.250655</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>-0.740767</td>\n",
       "      <td>3.239552</td>\n",
       "      <td>-0.340750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013952</td>\n",
       "      <td>-0.046892</td>\n",
       "      <td>-0.033836</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>-0.001545</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>635.666896</td>\n",
       "      <td>729.656746</td>\n",
       "      <td>689.965758</td>\n",
       "      <td>-0.010935</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>-0.048155</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332748</td>\n",
       "      <td>-7.048202</td>\n",
       "      <td>-0.284897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026525</td>\n",
       "      <td>-0.088072</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>636.584482</td>\n",
       "      <td>736.274307</td>\n",
       "      <td>689.997763</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>-0.041180</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.917586</td>\n",
       "      <td>6.617561</td>\n",
       "      <td>0.032005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trans_x   trans_y   trans_z     rot_x     rot_y     rot_z  global_signal  \\\n",
       "0  0.028576 -0.070269  0.002410 -0.002251 -0.001087  0.000333     637.338734   \n",
       "1  0.022116 -0.052498  0.014256 -0.002084 -0.001337  0.000482     636.074915   \n",
       "2  0.024887 -0.048753  0.014319 -0.001551 -0.001007  0.000895     635.334148   \n",
       "3  0.013952 -0.046892 -0.033836 -0.000980 -0.001545  0.000895     635.666896   \n",
       "4  0.026525 -0.088072 -0.034147 -0.000112 -0.001350  0.000510     636.584482   \n",
       "\n",
       "          csf  white_matter  trans_x_derivative1  trans_y_derivative1  \\\n",
       "0  739.137476    690.585770                  NaN                  NaN   \n",
       "1  733.465395    690.591405            -0.006459             0.017771   \n",
       "2  736.704948    690.250655             0.002771             0.003745   \n",
       "3  729.656746    689.965758            -0.010935             0.001861   \n",
       "4  736.274307    689.997763             0.012572            -0.041180   \n",
       "\n",
       "   trans_z_derivative1  rot_x_derivative1  rot_y_derivative1  \\\n",
       "0                  NaN                NaN                NaN   \n",
       "1             0.011847           0.000167          -0.000250   \n",
       "2             0.000063           0.000533           0.000330   \n",
       "3            -0.048155           0.000571          -0.000538   \n",
       "4            -0.000311           0.000869           0.000195   \n",
       "\n",
       "   rot_z_derivative1  global_signal_derivative1  csf_derivative1  \\\n",
       "0                NaN                        NaN              NaN   \n",
       "1           0.000149                  -1.263819        -5.672080   \n",
       "2           0.000413                  -0.740767         3.239552   \n",
       "3           0.000000                   0.332748        -7.048202   \n",
       "4          -0.000385                   0.917586         6.617561   \n",
       "\n",
       "   white_matter_derivative1  \n",
       "0                       NaN  \n",
       "1                  0.005635  \n",
       "2                 -0.340750  \n",
       "3                 -0.284897  \n",
       "4                  0.032005  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confound_df = confound_df[final_confounds]\n",
    "confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, we have `NaN`'s in our derivatives columns. This happens because there is no prior value to the first index to take a difference with, but this isn't a problem since we're going to be dropping 4 timepoints from our data and confounders anyway!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy TR Drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll implement our **Dummy TR Drop**. Remember this means that we are removing the first 4 timepoints from our functional image (we'll also have to do this for our first 4 confound timepoints!):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:13.374905Z",
     "iopub.status.busy": "2021-10-21T17:58:13.374158Z",
     "iopub.status.idle": "2021-10-21T17:58:14.316026Z",
     "shell.execute_reply": "2021-10-21T17:58:14.316585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 77, 49, 152)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we'll load in our data and check the shape\n",
    "raw_func_img = image.load_img(func_file)\n",
    "raw_func_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the fourth dimension represents frames/TRs(timepoints). We want to drop the first four timepoints entirely, to do so we use `nibabel`'s `slicer` feature. We'll also drop the first 4 confound variable timepoints to match the functional scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:14.321721Z",
     "iopub.status.busy": "2021-10-21T17:58:14.320979Z",
     "iopub.status.idle": "2021-10-21T17:58:15.842183Z",
     "shell.execute_reply": "2021-10-21T17:58:15.843030Z"
    }
   },
   "outputs": [],
   "source": [
    "func_img = raw_func_img.slicer[:,:,:,4:]\n",
    "func_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:15.867922Z",
     "iopub.status.busy": "2021-10-21T17:58:15.864182Z",
     "iopub.status.idle": "2021-10-21T17:58:15.873376Z",
     "shell.execute_reply": "2021-10-21T17:58:15.872772Z"
    }
   },
   "outputs": [],
   "source": [
    "#Drop confound dummy TRs\n",
    "drop_confound_df = confound_df.loc[4:]\n",
    "print(drop_confound_df.shape) #number of rows should match that of the functional image\n",
    "drop_confound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying confound regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to clean our data of our selected confound variables. There are two ways to go about this: \n",
    "\n",
    "1. If you have nilearn version 0.5.0 or higher use <code>nilearn.image.clean_img(image,confounds,...)</code>\n",
    "2. If you want full control over specific parts of the image you're cleaning use <code>nilearn.signal.clean(signals,confounds,...)</code> \n",
    "\n",
    "The first method is probably most practical and can be done in one line given what we've already set-up. However, in cases of very large datasets (HCP-style), the second method might be preferable for optimizing memory usage. \n",
    "\n",
    "We'll go over both\n",
    "***\n",
    "\n",
    "First note that both methods take an argument <code>confounds</code>. This is a matrix:\n",
    "\n",
    "$$\n",
    "\\left.\\left( \n",
    "\\vphantom{ \\begin{array}{c} 1 \\\\ 1 \\\\1 \\\\1 \\\\1 \\end{array} }\n",
    "\\smash{ \\underbrace{\n",
    "                    \\begin{array}{cccccc} \n",
    "                    a_1 & b_1 & c_1 & \\cdots & x_1 & \\\\\n",
    "                    a_2 & b_2 & c_2 & \\cdots & x_2 &\\\\\n",
    "                    a_3 & b_3 & c_3 & \\cdots & x_3 &\\\\\n",
    "                    \\vdots & \\vdots & \\vdots & \\dots & \\vdots &\\\\\n",
    "                    a_T & b_T & c_T & \\cdots & x_T & \n",
    "                    \\end{array}\n",
    "                   }_{ \\text{ # of confound variables }}\n",
    "      }\n",
    "\\right)\n",
    "\\right\\}\\,T\\text{ number of frames}\n",
    "$$\n",
    "<br></br>\n",
    "\n",
    "Therefore our goal is to take our confound matrix and work it into a matrix of the form above. The end goal is a matrix with 147 rows, and columns matching the number of confound variables (9x2=18)\n",
    "\n",
    "Luckily this is a one-liner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:15.880421Z",
     "iopub.status.busy": "2021-10-21T17:58:15.879174Z",
     "iopub.status.idle": "2021-10-21T17:58:15.883853Z",
     "shell.execute_reply": "2021-10-21T17:58:15.884519Z"
    }
   },
   "outputs": [],
   "source": [
    "confounds_matrix = drop_confound_df.values\n",
    "\n",
    "#Confirm matrix size is correct\n",
    "confounds_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean our image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Using <code>nilearn.image.clean_img</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll describe a couple of this function's important arguments. Any argument enclosed in `[arg]` is optional\n",
    "\n",
    "<code>nilearn.image.clean_img(image,confounds,[low_pass],[high_pass],[t_r],[mask_img],[detrend],[standardize])</code>\n",
    "\n",
    "**Required**:\n",
    "- <code>image</code>: The functional image (<code> func_img </code>)\n",
    "- <code>confounds</code>: The confound matrix (<code> confounds </code>) \n",
    "\n",
    "**Optional**:\n",
    "- <code>low_pass</code>: A low pass filter cut-off\n",
    "- <code>high_pass</code> A high pass filter cut-off\n",
    "- <code>t_r</code>: This is required if using low/high pass, the repetition time of acquisition (imaging metadata) \n",
    "- <code>mask_img</code> Apply a mask when performing confound regression, will speed up regression\n",
    "- <code>detrend</code>: Remove drift from the data (useful for removing scanner instability artifacts)\n",
    "- <code>standardize</code>: Set mean to 0, and variance to 1 --> sets up data for statistical analysis\n",
    "*** \n",
    "**What we're using**: \n",
    "\n",
    "The Repetition Time of our data is 2 seconds, in addition since we're replicating (mostly) Yeo 2011's analysis: \n",
    "- `high_pass = 0.009`\n",
    "- `low_pass = 0.08`\n",
    "- `detrend = True`\n",
    "- `standardize = True`\n",
    "\n",
    "In addition, we'll use a mask of our MNI transformed functional image (<code> mask </code>) to speed up cleaning \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:15.889701Z",
     "iopub.status.busy": "2021-10-21T17:58:15.888939Z",
     "iopub.status.idle": "2021-10-21T17:58:15.892131Z",
     "shell.execute_reply": "2021-10-21T17:58:15.891496Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set some constants\n",
    "high_pass= 0.009\n",
    "low_pass = 0.08\n",
    "t_r = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:15.898584Z",
     "iopub.status.busy": "2021-10-21T17:58:15.897475Z",
     "iopub.status.idle": "2021-10-21T17:58:27.024633Z",
     "shell.execute_reply": "2021-10-21T17:58:27.023956Z"
    }
   },
   "outputs": [],
   "source": [
    "#Clean!\n",
    "clean_img = image.clean_img(func_img,confounds=confounds_matrix,detrend=True,standardize=True,\n",
    "                         low_pass=low_pass,high_pass=high_pass,t_r=t_r, mask_img=mask_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.030297Z",
     "iopub.status.busy": "2021-10-21T17:58:27.029101Z",
     "iopub.status.idle": "2021-10-21T17:58:27.455801Z",
     "shell.execute_reply": "2021-10-21T17:58:27.455176Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's visualize our result! Doesn't really tell us much, but that's the data we're using for analysis!\n",
    "plotting.plot_epi(clean_img.slicer[:,:,:,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!\n",
    "\n",
    "Hopefully by now you've learned what confound regression is, and how to perform it in nilearn using 2 different methods. We'd like to note that there are many more methods to perform confound regression (simultaneous signal extraction + confound regression for example), but all those methods fundamentally rely on what you've done here. \n",
    "\n",
    "In addition, performing confound regression on *functional volumes* is also not the only way to do data cleaning. More modern methods involve applying confound regression on *functional surfaces*, however, those methods are too advanced for an introductory course to functional data analysis and involve tools outside of python. \n",
    "\n",
    "If you're interested in surface-based analysis we recommend that you check out the following sources:\n",
    "\n",
    "1. https://edickie.github.io/ciftify/#/\n",
    "2. https://www.humanconnectome.org/software/connectome-workbench\n",
    "3. [The minimal preprocessing pipelines for the Human Connectome Project](https://www.ncbi.nlm.nih.gov/pubmed/23668970)\n",
    "\n",
    "***\n",
    "\n",
    "The section below is **optional** and is a more advanced dive into the underlying mechanics of how `nilearn.clean_img` works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (OPTIONAL) Method 2: Using <code>nilearn.signal.clean</code>\n",
    "\n",
    "\n",
    "The arguments to this function are almost identical to <code>nilearn.image.clean_img</code>: \n",
    "\n",
    "<code>nilearn.signal.clean(signals,confounds,[low_pass],[high_pass],[t_r],[detrend],[standardize]</code> \n",
    "\n",
    "The only difference being:\n",
    "\n",
    "- <code>signals</code>: The resting state signals matrix\n",
    "- no <code>mask_img</code> argument exists, we'll have to pick which voxels to apply confound regression to ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.461014Z",
     "iopub.status.busy": "2021-10-21T17:58:27.459839Z",
     "iopub.status.idle": "2021-10-21T17:58:27.463501Z",
     "shell.execute_reply": "2021-10-21T17:58:27.462836Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load in nilearn.signal\n",
    "from nilearn import signal as sgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Set up our data signals matrix\n",
    "Recall our data is a 4D array, with the fourth dimension represented as time and the other 3 dimensions representing the (x,y,z) coordinate of a particular voxel. We want to convert this to a matrix represented as the following:\n",
    "\n",
    "$$\n",
    "\\left.\\left( \n",
    "\\vphantom{ \\begin{array}{c} 1 \\\\ 1 \\\\1 \\\\1 \\\\1 \\end{array} }\n",
    "\\smash{ \\underbrace{\n",
    "                    \\begin{array}{cccccc} \n",
    "                    a_1 & b_1 & c_1 & \\cdots & x_1 & \\\\\n",
    "                    a_2 & b_2 & c_2 & \\cdots & x_2 &\\\\\n",
    "                    a_3 & b_3 & c_3 & \\cdots & x_3 &\\\\\n",
    "                    \\vdots & \\vdots & \\vdots &\\cdots & \\vdots &\\\\\n",
    "                    a_T & b_T & c_T & \\cdots & x_T & \n",
    "                    \\end{array}\n",
    "                   }_{x*y*z \\text{ voxels }}\n",
    "      }\n",
    "\\right)\n",
    "\\right\\}\\,T\\text{ number of frames}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "- The **number of columns represents the total number of voxels (x\\*y\\*z)**, each column being a single voxel\n",
    "- The **number of rows represents the number of timepoints**\n",
    "\n",
    "So we need to *reshape* our data to match this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.468801Z",
     "iopub.status.busy": "2021-10-21T17:58:27.468050Z",
     "iopub.status.idle": "2021-10-21T17:58:27.471903Z",
     "shell.execute_reply": "2021-10-21T17:58:27.472419Z"
    }
   },
   "outputs": [],
   "source": [
    "#First we pull out our data as a numpy arrays\n",
    "func_data = func_img.get_data()\n",
    "\n",
    "#Then we get x,y,z dimensions\n",
    "x,y,z,t = func_data.shape\n",
    "\n",
    "#Then we get total number of voxels across all frames, x*y*z\n",
    "total_voxels = x*y*z\n",
    "\n",
    "#Then we reshape to the correct size, note that matrix is flipped on its side\n",
    "#Where the number of rows matches the number of voxels instead of time-series\n",
    "signals = func_data.reshape([total_voxels,t])\n",
    "print(signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.477164Z",
     "iopub.status.busy": "2021-10-21T17:58:27.476444Z",
     "iopub.status.idle": "2021-10-21T17:58:27.479424Z",
     "shell.execute_reply": "2021-10-21T17:58:27.479940Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now we flip it over (switch columns and rows) \n",
    "signals = signals.transpose() \n",
    "print(signals.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Masking our signals matrix (Optional)\n",
    "\n",
    "Using this <code>signals</code> matrix will work, but we'll also be cleaning *background/non-brain* voxels which may slow down our cleaning if we're cleaning hundreds (or *thousands* in the case of HCP) of images. \n",
    "\n",
    "To speed up the process we should only apply cleaning to the *subset of voxels that belong to the brain*. We can do this by masking out which voxels to apply cleaning to. This is equivalent to using <code>mask_img</code> in **Method 1** except we'll be doing this manually - it'll be slightly more complicated!.\n",
    "\n",
    "To apply the mask to our <code>signals</code>, we want our mask to be in a similar format to our <code>signals</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.484963Z",
     "iopub.status.busy": "2021-10-21T17:58:27.484275Z",
     "iopub.status.idle": "2021-10-21T17:58:27.492281Z",
     "shell.execute_reply": "2021-10-21T17:58:27.491721Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load in mask image\n",
    "mask_img = image.load_img(mask_file)\n",
    "\n",
    "#Pull out data matrix\n",
    "mask_data = mask_img.get_data()\n",
    "\n",
    "#Get dimensions of mask image\n",
    "mx, my, mz = mask_data.shape\n",
    "\n",
    "#Reshape the data so that each column corresponds to a voxel\n",
    "flattened_mask = mask_data.reshape([mx*my*mz])\n",
    "flattened_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result is a 1-dimensional array where each element corresponds to a voxel. Any element that is equal to 0 corresponds to a background voxel and any element corresponding to a brain voxel is equal to 1. \n",
    "To select which voxels to clean we'll find all the indices where <code>flattened_mask</code> equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.497357Z",
     "iopub.status.busy": "2021-10-21T17:58:27.496292Z",
     "iopub.status.idle": "2021-10-21T17:58:27.502126Z",
     "shell.execute_reply": "2021-10-21T17:58:27.501416Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the voxel indices (corresponding to column #s in our signals) that are non-zero (brain voxels) \n",
    "brain_voxels = flattened_mask.nonzero()[0] #nonzero() returns a tuple, we just want the array\n",
    "print(brain_voxels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Cleaning our data\n",
    "First we'll set up our filtering variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.507165Z",
     "iopub.status.busy": "2021-10-21T17:58:27.506179Z",
     "iopub.status.idle": "2021-10-21T17:58:27.508987Z",
     "shell.execute_reply": "2021-10-21T17:58:27.509499Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set up variables for confound regression\n",
    "low_pass = 0.08 \n",
    "high_pass = 0.009\n",
    "rep_time= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the actual cleaning once our data is set up will be very similar to <code>nilearn.image.clean_img</code> in form. The major difference will be that to mask our data we'll pick which indices to apply <code>nilearn.signal.clean</code> to using <code>brain_voxels</code>. \n",
    "\n",
    "*** \n",
    "\n",
    "In practice we'll do the following: \n",
    "1. Create an matrix of zeros matching our <code>signals</code>, we'll call it <code>cleaned_signals</code>\n",
    "2. In the voxels (columns) corresponding to <code>brain_voxels</code> write in the cleaned time-series\n",
    "\n",
    "Specifically, step 2 will be accomplished using the following:\n",
    "\n",
    "<code>cleaned_signals[:,brain_voxels] = nilearn.signal.clean(signals[:,brain_voxels],...)</code> \n",
    "\n",
    "Notice, <code>signals[:,brain_voxels]</code>, this does two things: \n",
    "1. Select all rows - **rows correspond to frames and we want all frames**\n",
    "2. Select the columns using <code>brain_voxels</code>. Remember **columns represent voxels, and <code>brain_voxels</code> corresponds to brain voxels**. \n",
    "\n",
    "Then <code>cleaned_signals[:,brain_voxels]</code> will select which voxels to write our cleaned time-series into. Notice that doing this sets our background voxels to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:27.514967Z",
     "iopub.status.busy": "2021-10-21T17:58:27.514081Z",
     "iopub.status.idle": "2021-10-21T17:58:36.105228Z",
     "shell.execute_reply": "2021-10-21T17:58:36.105799Z"
    }
   },
   "outputs": [],
   "source": [
    "#First create a matrix of zeroes that matches our signals matrix\n",
    "cleaned_signals = np.zeros_like(signals)\n",
    "\n",
    "#Apply only to brain voxels\n",
    "cleaned_signals[:,brain_voxels] = sgl.clean(signals[:,brain_voxels],confounds=confounds_matrix,\n",
    "                           detrend=True,standardize=True,\n",
    "                           low_pass=low_pass,high_pass=high_pass,\n",
    "                          t_r=rep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:36.110995Z",
     "iopub.status.busy": "2021-10-21T17:58:36.110106Z",
     "iopub.status.idle": "2021-10-21T17:58:36.112466Z",
     "shell.execute_reply": "2021-10-21T17:58:36.113055Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now we can reconstruct our volume, just perform operations in reverse\n",
    "#Step 1: Flip it back\n",
    "cleaned_signals = cleaned_signals.transpose() \n",
    "\n",
    "#Step 2: Reshape it back into a 4D time-series\n",
    "cleaned_brain = cleaned_signals.reshape([x,y,z,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:36.118747Z",
     "iopub.status.busy": "2021-10-21T17:58:36.117881Z",
     "iopub.status.idle": "2021-10-21T17:58:36.121039Z",
     "shell.execute_reply": "2021-10-21T17:58:36.121635Z"
    }
   },
   "outputs": [],
   "source": [
    "#The cleaned image generated from nilearn.signal.clean\n",
    "signals_cleaned_img = nib.Nifti1Image(cleaned_brain,np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:36.126771Z",
     "iopub.status.busy": "2021-10-21T17:58:36.125961Z",
     "iopub.status.idle": "2021-10-21T17:58:36.526472Z",
     "shell.execute_reply": "2021-10-21T17:58:36.527000Z"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_epi(signals_cleaned_img.slicer[:,:,:,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to <code>cleaned_img</code> which is what we generated using <code>nilearn.image.clean_img</code>. They should be identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T17:58:36.531880Z",
     "iopub.status.busy": "2021-10-21T17:58:36.531050Z",
     "iopub.status.idle": "2021-10-21T17:58:36.942888Z",
     "shell.execute_reply": "2021-10-21T17:58:36.942288Z"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_epi(clean_img.slicer[:,:,:,50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
